
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Wouter Kouw is a researcher in the Bayesian Intelligent Autonomous Systems lab at the Electrical Engineering department of TU Eindhoven. He has a dual background in neuroscience and computer science, and is most interested in neuro-inspired forms of artificial intelligence. His research focuses on designing, developing and analyzing probabilistic machine learning systems that learn from interactions with their environment, most notably active inference agents. Internally, these agents perform Bayesian inference by way of message passing in graphical models. They are deployed to mobile robots to assist humans with dangerous, dirty or dull work.\n","date":1756720800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1756720800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"2025-09-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Wouter Kouw is a researcher in the Bayesian Intelligent Autonomous Systems lab at the Electrical Engineering department of TU Eindhoven. He has a dual background in neuroscience and computer science, and is most interested in neuro-inspired forms of artificial intelligence. His research focuses on designing, developing and analyzing probabilistic machine learning systems that learn from interactions with their environment, most notably active inference agents. Internally, these agents perform Bayesian inference by way of message passing in graphical models. They are deployed to mobile robots to assist humans with dangerous, dirty or dull work.\n","tags":null,"title":"Wouter M. Kouw","type":"authors"},{"authors":["Wouter M. Kouw"],"categories":null,"content":"","date":1756720800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756720800,"objectID":"ad9c5f5d550a99fe3162f7a77476caae","permalink":"https://wmkouw.github.io/publication/hopt-bar/","publishdate":"2025-09-01T00:00:00Z","relpermalink":"/publication/hopt-bar/","section":"publication","summary":"We present a probabilistic numerical procedure for optimizing Matérn-class temporal Gaussian processes with respect to the kernel covariance function's hyperparameters based on Bayesian autoregression.","tags":[],"title":"Bayesian autoregression to optimize temporal Matérn-kernel Gaussian process hyperparameters","type":"publication"},{"authors":[],"categories":null,"content":"","date":1756717200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756717200,"objectID":"a2ff5e8b7476b703a183ec131cf9f9b6","permalink":"https://wmkouw.github.io/talk/bayesian-autoregression-to-optimize-temporal-matern-kernel-gaussian-process-hyperparameters/","publishdate":"2025-09-01T00:00:00Z","relpermalink":"/talk/bayesian-autoregression-to-optimize-temporal-matern-kernel-gaussian-process-hyperparameters/","section":"event","summary":"We present a procedure for optimizing Matérn kernel temporal Gaussian processes with respect to the kernel covariance function’s hyperparameters, based on Bayesian autoregressive filtering.","tags":["probabilistic-numerics","gaussian-processes","autoregressive-models"],"title":"Bayesian autoregression to optimize temporal Matérn kernel Gaussian process hyperparameters","type":"event"},{"authors":["Wouter M. Kouw","Tim Nisslbeck","Wouter Nuijten"],"categories":null,"content":"","date":1755252000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1755252000,"objectID":"acd3d8c6aa0655bd273030aa991582f1","permalink":"https://wmkouw.github.io/publication/marxefe-mp/","publishdate":"2025-08-15T00:00:00Z","relpermalink":"/publication/marxefe-mp/","section":"publication","summary":"We present the design of an autoregressive active inference agent in the form of message passing on a factor graph.","tags":[],"title":"Message passing-based inference in an autoregressive active inference agent","type":"publication"},{"authors":["Sepideh Adamiat","Wouter M. Kouw","Bert de Vries"],"categories":null,"content":"","date":1755252000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1755252000,"objectID":"0e381e88fe7f92bb633576f24243d0ba","permalink":"https://wmkouw.github.io/publication/snn-bern-mp/","publishdate":"2025-08-15T00:00:00Z","relpermalink":"/publication/snn-bern-mp/","section":"publication","summary":"We bridge the mathematical and the spike-based perspectives on brain functioning by designing spiking neural networks that simulate Bayesian inference through message passing for Bernoulli messages.","tags":[],"title":"Spike-timing dependent plasticity for Bernoulli message passing","type":"publication"},{"authors":["Tim Nisslbeck","Wouter M. Kouw"],"categories":null,"content":" ","date":1750672800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750672800,"objectID":"5e3977a8ea1c3c5b9084a51e5fb99694","permalink":"https://wmkouw.github.io/publication/marx-modeleval/","publishdate":"2025-06-23T00:00:00Z","relpermalink":"/publication/marx-modeleval/","section":"publication","summary":"We present a Forney-style factor graph representation for the class of multivariate autoregressive models with exogenous inputs, and propose an online Bayesian parameter-identification procedure based on message-passing within this graph.","tags":[],"title":"Factor graph-based online Bayesian identification and component evaluation for multivariate autoregressive exogenous input models","type":"publication"},{"authors":["Tim Nisslbeck","Wouter M. Kouw"],"categories":null,"content":"","date":1741341600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741341600,"objectID":"0e772890f56086d08e4883bf06a8a0bb","permalink":"https://wmkouw.github.io/publication/marx-mp/","publishdate":"2025-03-07T00:00:00Z","relpermalink":"/publication/marx-mp/","section":"publication","summary":"We propose a recursive Bayesian estimation procedure for multivariate autoregressive models with exogenous inputs based on message passing in a factor graph","tags":[],"title":"Online Bayesian system identification in multivariate autoregressive models via message passing","type":"publication"},{"authors":null,"categories":[],"content":"5EZC0 Math 3 - Probability \u0026amp; Statistics is a core Bachelor’s course in the Electrical Engineering Bachelor Program of the TU Eindhoven.\nMathematics is the foundation upon which engineering sciences are built and is at the core of disciplines that drive technological developments and innovations in the digital age. This course introduces students to the mathematics of probability and statistics, indispensable in the fields of communication, signal processing, control, and machine learning, among others. The student will learn about:\nRandom experiments and probability models (set theory, probability axioms, conditional probability, independence). Discrete random variables (probability mass function, cumulative distribution function, families of discrete random variables, functions of random variables, expectation, variance). Continuous random variables (probability density function, cumulative distribution function, families of continuous random variables, Gaussian random variables). Multiple (two) random variables (joint distributions, marginal distributions, conditional distributions, covariance, correlation, independence, Bivariate Gaussian random vectors). Stochastic processes (definitions, stationary processes, Poisson process, Gaussian process). Statistical inference (posterior distribution, MAP rule, least mean squares estimation). ","date":1735948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735948800,"objectID":"2ba717f169df2f99a581c942ebac8cfd","permalink":"https://wmkouw.github.io/teaching/tue-5ezc0/","publishdate":"2025-01-04T00:00:00Z","relpermalink":"/teaching/tue-5ezc0/","section":"teaching","summary":"**Math 3 - Probability \u0026 Statistics**: An electrical engineering BSc course that covers the basics of probability theory, probability distributions, estimators and stochastic processes.","tags":["probability-theory","statistics","stochastic-processes"],"title":"TU/e 5EZC0","type":"teaching"},{"authors":["Tim Nisslbeck","Wouter M. Kouw"],"categories":null,"content":"","date":1735639200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735639200,"objectID":"57ac37615aca5fd3228ded9e78359bcd","permalink":"https://wmkouw.github.io/publication/carx-efe/","publishdate":"2024-07-23T00:00:00Z","relpermalink":"/publication/carx-efe/","section":"publication","summary":"We propose an active inference agent, consisting of multiple scalar autoregressive model-based agents coupled by virtue of sharing memories, to learn and control a mechanical system with multiple bodies connected by joints.","tags":[],"title":"Coupled autoregressive active inference agents for control of multi-joint dynamical systems","type":"publication"},{"authors":["Sepideh Adamiat","Wouter M. Kouw","Bart van Erp","Bert de Vries"],"categories":null,"content":"","date":1735639200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735639200,"objectID":"af82bf2a4aad43fdea3041c5c35438d4","permalink":"https://wmkouw.github.io/publication/cartpole-mp/","publishdate":"2024-07-23T00:00:00Z","relpermalink":"/publication/cartpole-mp/","section":"publication","summary":"We describe a Bayesian controller for a cart-pole system, where the entire computational process consists of online Bayesian inference executed by message passing in factor graphs.","tags":[],"title":"Message passing-based Bayesian control of a cart-pole system","type":"publication"},{"authors":["Wouter M. Kouw"],"categories":null,"content":"","date":1735639200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735639200,"objectID":"06844fbe75eada02407242c377323df0","permalink":"https://wmkouw.github.io/publication/efe-nlamb/","publishdate":"2024-07-23T00:00:00Z","relpermalink":"/publication/efe-nlamb/","section":"publication","summary":"For expected free energy minimization, we show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation.","tags":[],"title":"Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents","type":"publication"},{"authors":null,"categories":null,"content":"Challenge. The International Labour Organisation reports over 300 million work-related accidents and diseases per year, with nearly 3 million being fatal (ILO report). Embodied Artificially Intelligent (EAI) agents can reduce this drastically, by for example inspecting construction sites or transporting cargo through hazardous areas. However, autonomously navigating unknown environments is difficult and requires adaptive decision-making. Suppose the agent detects a visually ambiguous obstacle: is it a crate that can be pushed away? Or a fence that needs to be navigated around? Rule-based algorithms and task-priority controllers could yield unsafe situations, while reinforcement learning (RL) requires enormous amounts of trial-and-error, potentially breaking the robot during training. The challenge is to design an EAI agent that cautiously and efficiently explores using multiple sensory modalities to find the best path through unknown terrain.\nFigure 1. Upon detection of an obstacle, external uncertainty (vision) increases. This uncertainty will be transferred to internal uncertainty (kinematic). The agent then minimizes kinematic uncertainty by making contact with the obstacle. Solution framework: brain-inspired multi-modal switching dynamics. We believe an agent should use touch for exploration when vision cannot resolve ambiguity in its environment (Figure 1). Mechanically, we envision an agent that transfers visual uncertainty about the external world (what is this obstacle in front of me?) to kinematic uncertainty internally (what will happen if I move my leg?), and then reacts with actions that minimize uncertainty (e.g., gently push object with leg). To create such an agent, we take inspiration from natural embodied intelligence and computational neuroscience, specifically Active Inference. An active inference agent operates on beliefs (probability distributions over unknown variables) and updates these using variational Bayesian inference when new data is observed. Using quantified uncertainty, actions are balanced between exploration (maximizing information gain during data acquisition) and exploitation (reaching a goal). It has been demonstrated to be a powerful framework for planning and navigation. Uncertainty also leads to caution: slow careful movements when uncertainty is high and rapid targeted movements when uncertainty is low.\nWe propose to design an active inference agent for a quadrupedal robot that incorporates visual perception, planning, decision-making and sensorimotor control (Figure 2). The active inference module learns two sets of dynamics: loco-motion and loco-manipulation. Visual perception is passed as a belief, expressed in terms of a factorized probability distribution, to the active inference module. Visual uncertainty is merged with the uncertainty in the loco-manipulation dynamics, akin to sensor fusion. When that uncertainty becomes large, the agent favours actions that minimize it in the future, such as manipulating the unknown object with its leg. Since the initial uncertainty will be high, the agent will make contact cautiously. Uncertainty shrinks with contact and a stronger action, such as pushing the object away, will be chosen, leading to a potentially improved locomotion path. In summary, the proposed active inference agent will use multiple modalities (vision, touch) to cautiously resolve ambiguity in the world and navigate the environment more robustly.\nFigure 2. Active inference agent overview. Vision-based uncertainty about the world affects kinematic uncertainty and triggers a switch to loco-manipulation, exploring the world through cautious touch. Planning implemented as message passing on a Forney-style factor graph (edges are random variables, nodes are operations) of switching autoregressive models. Implementation. The agent will have a vision, a control and a decision-making module (Figure 2). The vision module runs a simultaneous localization and mapping algorithm as well as rudimentary object detection. The planning and navigation module will switch between locomotion and loco-manipulation. During locomotion, it generates targets for a gait controller and guides the robot along the planned path. During loco-manipulation, it plans a series of cautious contact-rich policies that maximize information gain on the object and whether it can be pushed away. We will use switching autoregressive models, that are explainable in terms of the effect of input sources on output prediction, and for which information gain can be calculated analytically. Computations are distributed by means of reactive message passing on a Forney-style factor graph. This ensures computation cost is small enough to run in-situ (e.g., Raspberry Pi + NVIDIA Jetson) on a low-cost quadrupedal robot platform (e.g., Petoi Bittle), which we aim to demonstrate as proof-of-concept.\n","date":1734652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734652800,"objectID":"fbe98d1668b3da8efb1885a1722327d8","permalink":"https://wmkouw.github.io/project/contact-ai/","publishdate":"2024-12-20T00:00:00Z","relpermalink":"/project/contact-ai/","section":"project","summary":"CONTACT-AI aims to transform legged robots into contact-rich explorers, where legs are used to walk but also to cautiously manipulate the environment to resolve ambiguities in visual perception and navigate unknown terrain.","tags":["active-inference","quadrupedal-robot","embodied-ai"],"title":"CONTACT-AI","type":"project"},{"authors":["Chengfeng Jia","Jie Ma","Wouter M. Kouw"],"categories":null,"content":"","date":1730703600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730703600,"objectID":"e42869776aa59c4ba40ec84d0c0d9c85","permalink":"https://wmkouw.github.io/publication/kalman-gru/","publishdate":"2024-09-20T00:00:00Z","relpermalink":"/publication/kalman-gru/","section":"publication","summary":"We propose a Bayesian multiple model with an online model selection strategy to dynamically represent the latent motion modal from early observations. Each sub-model integrates a variational Kalman filter and Gated Recurrent Unit (GRU) neural network, enabling the estimation of time-varying transition coefficients and the process noise specific to different motion modalities.","tags":[],"title":"Multiple variational Kalman-GRU for ship trajectory prediction with uncertainty","type":"publication"},{"authors":[],"categories":null,"content":"","date":1726762800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726762800,"objectID":"61b5f599f8792e9ddb02ee602be81e03","permalink":"https://wmkouw.github.io/talk/embodied-artificial-intelligence-through-free-energy-minimization/","publishdate":"2024-09-19T00:00:00Z","relpermalink":"/talk/embodied-artificial-intelligence-through-free-energy-minimization/","section":"event","summary":"Artificial Intelligence should automate dangerous jobs instead of creative ones. I will present a framework for designing intelligent autonomous systems based on the Free Energy Principle, a leading physics-based theory of information processing in brains.","tags":["artificial-intelligence","free-energy"],"title":"Embodied artificial intelligence through free energy minimization","type":"event"},{"authors":[],"categories":null,"content":"","date":1726051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726051200,"objectID":"805bcaaeb753cea05d6f4bd9d2d2288a","permalink":"https://wmkouw.github.io/talk/planning-to-avoid-ambiguous-states-through-gaussian-approximations-to-non-linear-sensors/","publishdate":"2024-09-11T00:00:00Z","relpermalink":"/talk/planning-to-avoid-ambiguous-states-through-gaussian-approximations-to-non-linear-sensors/","section":"event","summary":"Gaussian approximations to nonlinear observation functions hat are sensitive to curvature, such as a second-order Taylor approximation, produce a state-dependent ambiguity term in expected free energy minimization.","tags":["active-inference","planning"],"title":"Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors","type":"event"},{"authors":["Wouter M. Kouw","Caspar Gruijthuijsen","Lennart Blanken","Enzo Evers","Timothy Rogers"],"categories":null,"content":"","date":1726048800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726048800,"objectID":"ab62a83df1382579032576847467a214","permalink":"https://wmkouw.github.io/publication/greybox-heat/","publishdate":"2024-06-04T00:00:00Z","relpermalink":"/publication/greybox-heat/","section":"publication","summary":"We propose a computational procedure for identifying convection in heat transfer dynamics of motion control systems, using a Gaussian Process Latent Force Model.","tags":[],"title":"Bayesian grey-box identification of convection effects in heat transfer dynamics","type":"publication"},{"authors":[],"categories":null,"content":"","date":1724322600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724322600,"objectID":"1343296b24fd1666f2b8f8e0d085de0b","permalink":"https://wmkouw.github.io/talk/bayesian-grey-box-identification-of-nonlinear-convection-effects-in-heat-transfer-dynamics/","publishdate":"2024-08-23T00:00:00Z","relpermalink":"/talk/bayesian-grey-box-identification-of-nonlinear-convection-effects-in-heat-transfer-dynamics/","section":"event","summary":"We propose a computational procedure for identifying convection in heat transfer dynamics based on a Gaussian process latent force model.","tags":["bayesian-filtering","system-identification"],"title":"Bayesian grey-box identification of nonlinear convection effects in heat transfer dynamics","type":"event"},{"authors":null,"categories":null,"content":"Not all data is equally useful. A major challenge in training artificially intelligent systems that learn from interactions with their environments (agents), is to acquire the most useful data points. For example, where should a robot look in order to pick up a cup? Active inference is a framework for designing agents that balance information-seeking and goal-seeking behaviour. This project will dive into the information-theoretic basis of this framework. We will attempt to answer questions such as:\nHow close to optimal is data acquisition based on maximizing information gain / minimizing expected free energy? Under what conditions is the active inference agent a consistent parameter estimator? Under what conditions is the active inference agent a stable controller? This position is supported by the Sectorplan Techniek of the Dutch Ministry of Education, Culture and Science.\n","date":1724112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724112000,"objectID":"7013eb8e7613ae3dfea21e42c951e344","permalink":"https://wmkouw.github.io/project/abias/","publishdate":"2024-08-20T00:00:00Z","relpermalink":"/project/abias/","section":"project","summary":"Analysis of Bayesian Intelligent Autonomous Systems focuses on the information-theoretic basis of Active Inference. What are the best data points for an agents? How optimal is data collection based on minimizing expected free energy?","tags":["active-inference","information-theory"],"title":"ABIAS","type":"project"},{"authors":[],"categories":null,"content":"","date":1720792800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720792800,"objectID":"7438ae680c396879c59682b156bbc404","permalink":"https://wmkouw.github.io/talk/information-seeking-polynomial-narx-model-predictive-control-through-free-energy-minimization/","publishdate":"2024-07-09T00:00:00Z","relpermalink":"/talk/information-seeking-polynomial-narx-model-predictive-control-through-free-energy-minimization/","section":"event","summary":"We propose an adaptive model-predictive controller that balances driving the system to a goal state and seeking system observations that are informative with respect to the parameters of a nonlinear autoregressive exogenous model.","tags":["bayesian-filtering","system-identification","active-inference"],"title":"Information-seeking polynomial NARX model-predictive control through free energy minimization","type":"event"},{"authors":[],"categories":null,"content":"","date":1717162200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717162200,"objectID":"ca08df7f73dd468e34d54958eee4c567","permalink":"https://wmkouw.github.io/talk/bayesian-machine-learning-for-embodied-artificial-intelligence/","publishdate":"2024-05-31T00:00:00Z","relpermalink":"/talk/bayesian-machine-learning-for-embodied-artificial-intelligence/","section":"event","summary":"Presentation on personal research profile. I discussed active inference agents, and their application to mobile robotics as forms of embodied artificial intelligence. I discussed the quadrupedal robot locomotion project, including open challenges, and briefly showed our reactive message passing toolbox RxInfer,jl.","tags":[],"title":"Bayesian machine learning for embodied artificial intelligence","type":"event"},{"authors":[],"categories":null,"content":"","date":1713187800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713187800,"objectID":"48f91bcdef12d7eb2521b81558268f92","permalink":"https://wmkouw.github.io/talk/natural-ai-for-control-and-mobile-robotics/","publishdate":"2024-04-16T00:00:00Z","relpermalink":"/talk/natural-ai-for-control-and-mobile-robotics/","section":"event","summary":"Natural AI is Artificial Intelligence based on physics principles. The Free Energy Principle allows for designing agents that learn in real-time, are low-power and are explainable. They are powered by Bayesian mechanics, updating beliefs over states of the world and actions as data streams in. At BIASlab and LazyDynamics, we have developed a toolbox for scalable automatic Bayesian inference called RxInfer.","tags":["bayesian-filtering","free-energy","variational-bayes"],"title":"Natural AI for control and mobile robotics","type":"event"},{"authors":["Chengfeng Jia","Jie Ma","Bert de Vries","Wouter M. Kouw"],"categories":null,"content":"","date":1712041200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712041200,"objectID":"c2ce69acc1ceeb843c38f1fb7c1fc73d","permalink":"https://wmkouw.github.io/publication/intent-mp/","publishdate":"2023-09-10T00:00:00Z","relpermalink":"/publication/intent-mp/","section":"publication","summary":"We propose a probabilistic graph model and perform message passing to infer the hidden avoidance intent of ships during encounters.","tags":[],"title":"Bayesian inference of collision avoidance intent during ship encounters","type":"publication"},{"authors":["Wouter M. Kouw"],"categories":null,"content":"","date":1703487600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1703487600,"objectID":"691c4bac1278f2f83f428fd2ca5e4962","permalink":"https://wmkouw.github.io/publication/narx-efe/","publishdate":"2023-12-27T00:00:00Z","relpermalink":"/publication/narx-efe/","section":"publication","summary":"An adaptive model-predictive controller that balances driving the system to a goal state and seeking system observations that are informative with respect to the parameters of a nonlinear autoregressive exogenous model.","tags":[],"title":"Information-seeking polynomial NARX model-predictive control through expected free energy minimization","type":"publication"},{"authors":[],"categories":null,"content":"","date":1682515800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682515800,"objectID":"336b15c2bda91634669094593c3adeca","permalink":"https://wmkouw.github.io/talk/variational-bayesian-inference-for-system-identification/","publishdate":"2023-04-26T09:00:00Z","relpermalink":"/talk/variational-bayesian-inference-for-system-identification/","section":"event","summary":"In the Bayesian approach to modelling, noise is not considered a nuisance but rather a reflection of uncertainty, expressed in terms of probability distributions. Variational Bayesian inference optimizes an approximation of the posterior distribution, allowing for a trade-off between accuracy and computational workload. In this talk, I will demonstrate how this technique may be applied in a simple system identification problem, compare it to classical techniques, and illustrate how modularity may be utilized to accelerate the model design cycle.","tags":["variational-bayes","system-identification"],"title":"Variational Bayesian inference for system identification","type":"event"},{"authors":null,"categories":[],"content":"5XIF0 Neuro Computation is an elective course in the Electrical Engineering Bachelor Program of the TU Eindhoven and a core course in the Neuro System Design package of the Neuro Engineering track.\nThe human brain and other biological neural systems are incredibly efficient at processing information, can handle complex and noisy data inputs, learn quickly, and adapt to new situations while operating in a highly parallel and distributed manner. This is very different than the current artificial intelligence approach, which requires too much power and does not scale. Thus, efforts are underway to develop artificial neural networks that can approach the efficiency and effectiveness of biological neural systems. These efforts include research in neurocomputing and include the development of new theories, methods, and algorithms in designing more specialized ’neuromorphic’ hardware architectures that support bio-inspired neural networks.\nIn 5XIF0 Neuro Computation you will have the opportunity to learn the computational properties of neurobiological systems and you will learn to design spiking neural networks using mixed-signal “neuromorphic” electronic circuits. Similar to their biological counterparts, these neuromorphic implementations operate in continuous time in a massively parallel way, are extremely efficient, and represent the third generation of neural networks.\n","date":1681862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735948800,"objectID":"828fc60a5b3549d515e13b802fbe4a1f","permalink":"https://wmkouw.github.io/teaching/tue-5xif0/","publishdate":"2023-04-19T00:00:00Z","relpermalink":"/teaching/tue-5xif0/","section":"teaching","summary":"**Neuro Computation**: a BSc course covering the computational properties of neurobiological systems and how to design spiking neural networks using mixed-signal \"neuromorphic\" electronic circuits.","tags":["Neurobiology","Computational architecture","Neuromorphic computing"],"title":"TU/e 5XIF0","type":"teaching"},{"authors":["Albert Podusenko","Semih Akbayrak","Ismail Senoz","Maarten Schoukens","Wouter M. Kouw"],"categories":null,"content":"","date":1659682800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659682800,"objectID":"c2dad13700b84138c05e5a852c31cd7d","permalink":"https://wmkouw.github.io/publication/ln-narmax/","publishdate":"2022-08-05T00:00:00Z","relpermalink":"/publication/ln-narmax/","section":"publication","summary":"We present a Bayesian identification procedure for polynomial NARMAX models based on message passing on a factor graph.","tags":[],"title":"Message-passing-based system identification for NARMAX models","type":"publication"},{"authors":["Alp Sarı","Tak Kaneko","Lense Swaenen","Wouter M. Kouw"],"categories":null,"content":"","date":1659348000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659348000,"objectID":"1c608bf67c83479371e2112423462449","permalink":"https://wmkouw.github.io/publication/rsot-st/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/publication/rsot-st/","section":"publication","summary":"We address the robustness of the current state-of-the-art radar object trackers and propose a modification by modelling process noise with a distribution that has heavier tails than a Gaussian.","tags":[],"title":"Variational Bayes for robust radar single object tracking","type":"publication"},{"authors":[],"categories":null,"content":"","date":1654788600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654788600,"objectID":"4eabdb39862e7f34071569589df48afe","permalink":"https://wmkouw.github.io/talk/variational-message-passing-for-online-bayesian-narmax-identification/","publishdate":"2022-06-08T09:00:00Z","relpermalink":"/talk/variational-message-passing-for-online-bayesian-narmax-identification/","section":"event","summary":"We propose a variational message passing inference algorithm for online system identification using polynomial NARMAX models. We show empirically that our variational Bayesian estimator outperforms an online recursive least-squares estimator, most notably in small sample size settings and low noise regimes, and performs on par with an iterative least-squares estimator trained offline.","tags":["bayesian-filtering","system-identification","message-passing"],"title":"Variational message passing for online Bayesian NARMAX identification","type":"event"},{"authors":["Wouter M. Kouw","Albert Podusenko","Magnus Koudahl","Maarten Schoukens"],"categories":null,"content":"","date":1643709600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643709600,"objectID":"f7db47a4765cb9a40c51ac5d0873e7e7","permalink":"https://wmkouw.github.io/publication/vmpnarmax/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/vmpnarmax/","section":"publication","summary":"We propose a variational message passing algorithm for estimating coeffcients of a polynomial NARMAX model, which outperforms a recursive least-squares estimator.","tags":[],"title":"Variational message passing for online polynomial NARMAX identification","type":"publication"},{"authors":null,"categories":null,"content":"We will design an artificially intelligent autonomous system for quadrupedal robot locomotion, using a novel paradigm from theoretical neuroscience called Active Inference (AIF). “Active” refers to selecting actions that reduce uncertainty within the probabilistic model of the world and “inference” refers to the use of variational Bayesian inference to update beliefs over unobserved variables in the model (e.g. parameters, states, noise, controls). AIF is a novel perspective on neural information processing and is intended to model cognition, for instance how rats explore small mazes in search of food. But it can also serve as a design principle for artificially intelligent autonomous systems (agents). These can be applied to signal processing systems (e.g. adaptively calibrating hearing aids), control systems (e.g. identifying electro-mechanical systems) or robotics (e.g. learning to grasp). However, bringing AIF to engineering is far from trivial. There are many technical challenges, such as how to account for strong non-linearities, how to deal with high degrees of freedom of moving parts or how to include practical constraints to avoid breaking hardware.\nWhy Active Inference? It represents a series of technical advantages over the current state-of-the-art in AI methodologies. Deep learning is a popular framework with impressive applications, but is not without its limitations. Firstly, it requires huge amounts of data to “discover” structure. AIF is a hybrid of model-driven and data-driven learning, which means it can rely on prior knowledge when data is scarce. Crucially, deep learning methods only perform well after an experienced designer has extensively tuned the network’s architecture, regularized its complexity and tried various optimizers. In AIF, there are fewer model parameters, regularization arises naturally through prior distributions and optimization is not an issue. To train deep neural networks, you need expensive hardware (GPU) with a sizeable carbon footprint. AIF agents require less computation power and are more suited to embedded electronics. Last but not least, when deep learning is applied to control (deep reinforcement learning), the engineer must design a “reward function” that indicates the value of actions. This function is hard to design, leading to misbehaving agents. AIF agents do not suffer from this problem because rewards arise implicitly from the probabilistic model. These properties are all nice, but the most important argument for AIF is that it represents a principled way to design intelligent systems: instead of hacking something together based on task-specific cost functions, we now have a first-principle-based framework of perception, decision-making, planning and action.\nWhy quadrupedal walking robots? Because unlike wheeled robots, walkers can step over objects and climb stairs. Unlike drones, they can enter confined spaces and operate for extended periods of time. In theory, quadrupeds are highly agile. In practice, learning to walk is such a complex challenge that they often fail to live up to their potential. Modern AI has accelerated legged robotics to the point that quadrupeds now walk relatively smoothly. Companies such as Boston Dynamics, ANYbotics and Unitree are developing commercial products for semi-autonomous site inspection and maintenance. But their controllers still rely heavily on deep learning. Our AIF agent will make it much easier to teach legged robots to walk.\nHow will the proposed agent work? AIF agents are based on a probabilistic graphical model expressing the dependence of observed and unknown variables through conditional distributions. For dynamical systems, there are leaf nodes representing initial conditions that are specified as “prior beliefs”. One can estimate the posterior distributions for the unknowns (e.g. states, parameters, noises) through Bayesian inference, usually in the form of a message-passing algorithm. Sometimes, the integrals involved are intractable. Variational inference solves this by approximating the posteriors with a simpler “recognition model”. AIF agents are essentially a form of variational Bayesian inference on probabilistic graphical models of dynamic systems that alternate between solving a signal processing (perception) and a control (action) problem to reach a goal.\nThe position is supported by the Sectorplan Techniek of the Dutch Ministry of Education, Culture and Science and the Eindhoven Artificial Intelligence Systems Institute.\n","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"61c7b5b20c279d2d7bedecbff1a75a59","permalink":"https://wmkouw.github.io/project/fep-quad/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/project/fep-quad/","section":"project","summary":"Design of an intelligent autonomous system for quadrupedal robot locomotion using Active Inference (AIF). AIF is a neuroscience-based framework of perception and action, and could bring us closer to how animals learn to walk.","tags":["active-inference","quadrupedal-robot","embodied-ai"],"title":"FEPQuad","type":"project"},{"authors":["Magnus Koudahl","Wouter M. Kouw","Bert de Vries"],"categories":null,"content":"","date":1637748000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637748000,"objectID":"0b171a7d0325796e42f7dd663c543772","permalink":"https://wmkouw.github.io/publication/efe-glds/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/efe-glds/","section":"publication","summary":"Active Inference (AIF) is a framework that can be used both to describe information processing in naturally intelligent systems, such as the human brain, and to design synthetic intelligent systems (agents). In this paper we show that Expected Free Energy (EFE) minimisation, a core feature of the framework, does not lead to purposeful explorative behaviour in linear Gaussian dynamical systems. We provide a simple proof that, due to the specific construction used for the EFE, the terms responsible for the exploratory (epistemic) drive become constant in the case of linear Gaussian systems. This renders AIF equivalent to KL control. From a theoretical point of view this is an interesting result since it is generally assumed that EFE minimisation will always introduce an exploratory drive in AIF agents. While the full EFE objective does not lead to exploration in linear Gaussian dynamical systems, the principles of its construction can still be used to design objectives that include an epistemic drive. We provide an in-depth analysis of the mechanics behind the epistemic drive of AIF agents and show how to design objectives for linear Gaussian dynamical systems that do include an epistemic drive. Concretely, we show that focusing solely on epistemics and dispensing with goal-directed terms leads to a form of maximum entropy exploration that is heavily dependent on the type of control signals driving the system. Additive controls do not permit such exploration. From a practical point of view this is an important result since linear Gaussian dynamical systems with additive controls are an extensively used model class, encompassing for instance Linear Quadratic Gaussian controllers. On the other hand, linear Gaussian dynamical systems driven by multiplicative controls such as switching transition matrices do permit an exploratory drive.","tags":[],"title":"On epistemics in expected free energy for linear Gaussian state space models","type":"publication"},{"authors":["Albert Podusenko","Wouter M. Kouw","Bert de Vries"],"categories":null,"content":"","date":1622160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622160000,"objectID":"c9f89d9063002169dfbc3850147101d0","permalink":"https://wmkouw.github.io/publication/tvar/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/tvar/","section":"publication","summary":"Time-varying autoregressive (TVAR) models are widely used for modeling of non-stationary signals. Unfortunately, online joint adaptation of both states and parameters in these models remains a challenge. In this paper, we represent the TVAR model by a factor graph and solve the inference problem by automated message passing-based inference for states and parameters.","tags":[],"title":"Message passing-based inference for time-varying autoregressive models","type":"publication"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1621468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621468800,"objectID":"0ca06fbf957a046929f5cba1dc6c8863","permalink":"https://wmkouw.github.io/publication/rdada/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/rdada/","section":"publication","summary":"Consider a domain-adaptive supervised learning setting, where a classifier learns from labeled data in a source domain and unlabeled data in a target domain to predict the corresponding target labels. If the classifier’s assumption on the relationship between domains (e.g. covariate shift, common subspace, etc.) is valid, then it will usually outperform a non-adaptive source classifier. If its assumption is invalid, it can perform substantially worse. Validating assumptions on domain relationships is not possible without target labels. We argue that, in order to make domain-adaptive classifiers more practical, it is necessary to focus on robustness; robust in the sense that an adaptive classifier will still perform at least as well as a non-adaptive classifier without having to rely on the validity of strong assumptions. With this objective in mind, we derive a conservative parameter estimation technique, which is transductive in the sense of Vapnik and Chervonenkis, and show for discriminant analysis that the new estimator is guaranteed to achieve a lower risk on the given target samples compared to the source classifier. Experiments on problems with geographical sampling bias indicate that our parameter estimator performs well.","tags":[],"title":"Robust domain-adaptive discriminant analysis","type":"publication"},{"authors":null,"categories":[],"content":"5XSL0 Fundamentals of Machine Learning (BMLIP) is an elective course in the Electrical Engineering Bachelor Program of the TU Eindhoven.\nWe live in the age of data. The amount of data has been increasing at an exponential rate over the last decades and is expected to continue. Not only is the volume of the data larger than ever before, also the variety in types of data is consistently growing. Due to the enormous progress in sensor technology, we can measure more than ever before. The vast amounts of heterogeneous data harbor useful information that can help in e.g. clinical decision-making, predictive maintenance and visual object detection. However, due to its growing volume and complexity, it becomes increasingly harder for humans to extract this information by manually analyzing the patterns in the data. Machine learning is a subfield of Artificial Intelligence (AI) that focuses on building mathematical models that can extract information from data.\nThis course aims to offer a solid theoretical basis for modern machine learning methods. It will teach students the mathematical foundations of machine learning, introduce a number of elementary techniques and discuss methods for evaluation of model performance. These concepts are the fundamental building blocks of modern AI approaches and offer important insights.\n","date":1618790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641254400,"objectID":"bf036b366cf221caab822bca93a9996f","permalink":"https://wmkouw.github.io/teaching/tue-5xsl0/","publishdate":"2021-04-19T00:00:00Z","relpermalink":"/teaching/tue-5xsl0/","section":"teaching","summary":"**Fundamentals of Machine Learning**: a BSc course that covers the basics of machine learning, including linear classification and regression, support vector machines, random forests, and neural networks.","tags":["Machine Learning","Risk Minimization","Neural Networks"],"title":"TU/e 5XSL0","type":"teaching"},{"authors":null,"categories":null,"content":"Computation in biological brain tissue consumes several orders of magnitude less power than silicon-based systems. Motivated by this fact, this project aims to develop the world’s first hybrid neuro-in-silico Artificial Intelligence (AI) computer, introducing a fundamentally new paradigm of AI computing. In this high-risk high-gain project, we will combine an in-silico Bayesian control agent (BCA) with neural tissue hosted by a microfluidic Brain-on-Chip (BoC) that together form a hybrid learning system capable of solving real-world AI problems.\nAll computation and communication inside and between the BCA and BoC will be governed by the Free Energy Principle, which is both the leading neuroscientific theory for describing biological neuronal processes and supports a variational Bayesian machine learning interpretation. We will start by developing a pure silicon-based BCA that learns to balance an inverted pendulum, implemented by free energy minimization on a factor graph. Next, we will replace successively larger parts of the factor graph with biological neural circuits of a microfluidic multi-compartment BoC device. The biological network will be trained by electrical stimulation orchestrated by the synthetic Bayesian agent. For the communication between these two units, we will design and realize a novel communication protocol making use of existing software being applied in readout and event sorting for Calcium imaging and multi-electrode array data, such as MEAViewer, CALIMA, NetCal and SpikeHunter. By upscaling the number of replaced sub-circuits, we aim to provide a proof-of-concept and to lay the basis for ultra-low power hybrid brain-on-chip AI computing.\nThis position is supported by the Exploratory Multidiscplinary AI Research Program of the Eindhoven Artificial Intelligence Systems Institute.\n","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"487245259943cf7b0f3e2e200e33a20a","permalink":"https://wmkouw.github.io/project/bayesbrain/","publishdate":"2021-04-01T00:00:00Z","relpermalink":"/project/bayesbrain/","section":"project","summary":"Computation in biological brain tissue consumes several orders of magnitude less power than silicon-based systems. Motivated by this fact, this project aims to develop the world’s first hybrid neuro-in-silico Artificial Intelligence (AI) computer.","tags":["active-inference","neural-computation","brain-on-chip"],"title":"BayesBrain","type":"project"},{"authors":[],"categories":null,"content":"","date":1611232200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611232200,"objectID":"ace9f0cfa05d81e6a31eda041d38c7ca","permalink":"https://wmkouw.github.io/talk/target-robust-discriminant-analysis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/target-robust-discriminant-analysis/","section":"event","summary":"Validating assumptions on domain relationships is not possible without target labels. We argue that, in order to make domain-adaptive classifiers more practical, it is necessary to focus on robustness; robust in the sense that an adaptive classifier will still perform at least as well as a non-adaptive classifier without having to rely on the validity of strong assumptions.","tags":["domain-adaptation","discriminant-analysis"],"title":"Target robust discriminant analysis","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"ce0563cc597d77bf8efda20150cff54a","permalink":"https://wmkouw.github.io/publication/trda/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/trda/","section":"publication","summary":"Often, in practice, the data distribution at test time differs, to a smaller or larger extent, from that of the original training data. Consequentially, the so-called source classifier, trained on the labeled data, deteriorates on the test, or target data. Domain adaptive classifiers aim to alleviate this problem, but typically  assume a particular type of domain shift. Most are not robust to violations of domain shift assumptions and may perform even worse than the non-adaptive source classifier. We construct robust parameter estimators for discriminant analysis that guarantee performance improvements of the adaptive classifier over the source classifier.","tags":[],"title":"Target robust discriminant analysis","type":"publication"},{"authors":[],"categories":null,"content":"","date":1604588400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604588400,"objectID":"951dfe306e82270aa59288a9a0251c57","permalink":"https://wmkouw.github.io/talk/variational-bayes-for-signal-processing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/variational-bayes-for-signal-processing/","section":"event","summary":"A talk for the Optimization / Machine Learning Competence group at Sioux Technologies. I presented the derivations to make a Bayesian filter for a standard Gaussian linear dynamical system, and outlined variational Bayesian inference as an extension. I briefly showed some of BIASlab's research.","tags":["bayesian-filtering","kalman-filter","variational-bayes","signal-processing"],"title":"Variational Bayes for signal processing","type":"event"},{"authors":[],"categories":null,"content":"","date":1599993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599993600,"objectID":"a2818e0cce47b67b4816e591536f673f","permalink":"https://wmkouw.github.io/talk/online-system-identification-in-a-duffing-oscillator-using-free-energy-minimisation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/online-system-identification-in-a-duffing-oscillator-using-free-energy-minimisation/","section":"event","summary":"A paper on online system identification, where I cast the nonlinear stochastic diﬀerential equation of a Duﬃng oscillator to a probabilistic graphical model and use variational message passing to infer dynamical parameters of the system.","tags":["system-identification","free-energy-minimisation","bayesian-filtering"],"title":"Online system identification in a Duffing oscillator using free energy minimisation","type":"event"},{"authors":["Wouter M. Kouw"],"categories":null,"content":" ","date":1598954400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598954400,"objectID":"8b9ce2a6989f99907bc57f09cdce8760","permalink":"https://wmkouw.github.io/publication/nsi-duff/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/nsi-duff/","section":"publication","summary":"Online system identification is the estimation of parameters of a dynamical system, such as mass or friction coefficients, for each measurement of the input and output signals. Here, the nonlinear stochastic differential equation of a Duffing oscillator is cast to a generative model and dynamical parameters are inferred using variational message passing on a factor graph of the model. The approach is validated with an experiment on data from an electronic implementation of a Duffing oscillator. The proposed inference procedure performs as well as offline prediction error minimisation in a state-of-the-art nonlinear model.","tags":[],"title":"Online system identification in a Duffing oscillator by free energy minimisation","type":"publication"},{"authors":["Evelien Hart","Rens van de Schoot","Wouter M. Kouw","Duco Veen","Adriënne Mendrik"],"categories":null,"content":"","date":1597140000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597140000,"objectID":"27775f2db6aca9f7855928b03878d69c","permalink":"https://wmkouw.github.io/publication/drc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/drc/","section":"publication","summary":"In a broad range of fields it may be desirable to reuse a supervised classification algorithm and apply it to a new data set. However, generalization of such an algorithm and thus achieving a similar classification performance is only possible when the training data used to build the algorithm is similar to new unseen data one wishes to apply it to. It is often unknown in advance how an algorithm will perform on new unseen data, being a crucial reason for not deploying an algorithm at all. Therefore, tools are needed to measure the similarity of data sets. In this paper, we propose the Data Representativeness Criterion (DRC) to determine how representative a training data set is of a new unseen data set. We present a proof of principle, to see whether the DRC can quantify the similarity of data sets and whether the DRC relates to the performance of a supervised classification algorithm. We compared a number of magnetic resonance imaging (MRI) data sets, ranging from subtle to severe difference is acquisition parameters. Results indicate that, based on the similarity of data sets, the DRC is able to give an indication as to when the performance of a supervised classifier decreases. The strictness of the DRC can be set by the user, depending on what one considers to be an acceptable underperformance.","tags":[],"title":"The data representativeness criterion","type":"publication"},{"authors":["Albert Podusenko","Wouter M. Kouw","Bert de Vries"],"categories":null,"content":" ","date":1592733600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592733600,"objectID":"a1697a54c07afa6600af38510cf343c3","permalink":"https://wmkouw.github.io/publication/vmphar/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/vmphar/","section":"publication","summary":"In this paper, we track states and parameters in a hierarchical AR filter by means of variational message passing (VMP) in a factor graph. We derive VMP update rules for an \"AR node\" that can be re-used at various hierarchical levels and supports automated message passing-based inference for states and parameters.","tags":[],"title":"Online variational message passing in hierarchical autoregressive models","type":"publication"},{"authors":["Ismail Senoz","Albert Podusenko","Wouter M. Kouw","Bert de Vries"],"categories":null,"content":" ","date":1591833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591833600,"objectID":"aa32ef30ecd76add48fd940075655d3e","permalink":"https://wmkouw.github.io/publication/vmpar-hgf/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/vmpar-hgf/","section":"publication","summary":"We address the problem of online Bayesian state and parameter tracking in autoregressive (AR) models with time-varying process noise variance. The involved marginalization and expectation integrals cannot be analytically solved. Moreover, the online tracking constraint makes sampling and batch learning methods unsuitable for this problem. We propose a hybrid variational message passing algorithm that robustly tracks the time-varying dynamics of the latent states, AR coefficients and process noise variance. Since message passing in a factor graph is a highly modular inference approach, the proposed methods easily extend to other non-stationary dynamic modeling problems.","tags":[],"title":"Bayesian joint state and parameter tracking in autoregressive models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1585670400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585670400,"objectID":"7b8cfea418a22b021e8535fff6a5d5d3","permalink":"https://wmkouw.github.io/talk/schedule-free-variational-message-passing-for-bayesian-filtering/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/schedule-free-variational-message-passing-for-bayesian-filtering/","section":"event","summary":"Message passing on factor graphs typically relies on a scheduling procedure, in which a central algorithm or compiler figures out _which_ nodes should pass messages _where_ at _what_ time. This is not a biologically plausible mechanism. I explore the possibility of passing messages without a scheduler, where the nodes merely \"react\" to incoming messages.","tags":["variational-bayes","bayesian-filtering","message-passing"],"title":"Schedule-free variational message passing for Bayesian filtering","type":"event"},{"authors":null,"categories":[],"content":"5SSD0 Bayesian Machine Learning \u0026amp; Information Processing (BMLIP) is a course in the Electrical Engineering Master programme of TU Eindhoven.\nBMLIP covers the fundamentals of the Bayesian (i.e., probabilistic) approach to machine learning and information processing systems. Firstly, we discuss many useful models including common regression and classification methods, Gaussian mixture models, hidden Markov models and Kalman filters. Secondly, we teach Expectation-Maximization (EM), Variational Bayes (VB) and Variational Message Passing (VMP). Lastly, we discuss intelligent agents that learn purposeful behavior from interactions with their environment.\nI teach the lectures on Probabilistic Programming, where students write software for automatic inference in probabilistic models.\n","date":1579132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735948800,"objectID":"55ea80ee1c118785a0ece2eb3574e690","permalink":"https://wmkouw.github.io/teaching/tue-5ssd0/","publishdate":"2020-01-16T00:00:00Z","relpermalink":"/teaching/tue-5ssd0/","section":"teaching","summary":"**Bayesian Machine Learning \u0026 Information Processing**: a MSc course that covers the fundamentals of the Bayesian (i.e., probabilistic) approach to machine learning and information processing systems.","tags":["Bayesian Inference","Probabilistic Programming","Probabilistic Graphical Models"],"title":"TU/e 5SSD0","type":"teaching"},{"authors":["Johannes Bjerva","Wouter M. Kouw","Isabelle Augenstein"],"categories":null,"content":"","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"98420b2263f79120980c8c911ab69c00","permalink":"https://wmkouw.github.io/publication/sa-nlp/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sa-nlp/","section":"publication","summary":"Language evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO' in publications refer to neural network architectures rather than persons. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences (regular intervals) or author stance prediction for rumours on Twitter (irregular intervals). Inspired by successes in computer vision, we tackle data drift by sequentially aligning learned representations. %We consider both unsupervised and semi-supervised alignment. We evaluate on three challenging tasks varying in terms of time-scales, linguistic units, and domains. These tasks show our method outperforming several strong baselines, including using all available data. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution.","tags":[],"title":"Back to the future - temporal adaptation of text representations","type":"publication"},{"authors":[],"categories":null,"content":"","date":1571061600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571061600,"objectID":"e598b7366a926dbdf9c8e2e4f769c726","permalink":"https://wmkouw.github.io/talk/robust-importance-weighted-cross-validation-under-sample-selection-bias/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/robust-importance-weighted-cross-validation-under-sample-selection-bias/","section":"event","summary":"Importance-weighted cross-validation produces sub-optimal hyperparameter estimates in problem settings where large weights arise with high probability. We introduce a control variate to increase its robustness to problematically large weights.","tags":["importance-weighting","cross-validation","sample-selection-bias"],"title":"Robust importance-weighted cross-validation under sample selection bias","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":"","date":1570406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570406400,"objectID":"e98c82fc56d50df2097e93fb9bed32a9","permalink":"https://wmkouw.github.io/publication/da-rev/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/da-rev/","section":"publication","summary":"Domain adaptation has become a prominent problem setting in machine learning and related fields. This review asks the question: how can a classifier learn from a source domain and generalize to a target domain? We present a categorization of approaches, divided into, what we refer to as, sample-based, feature-based and inference-based methods. Sample-based methods focus on weighting individual observations during training based on their importance to the target domain. Feature-based methods revolve around on mapping, projecting and representing features such that a source classifier performs well on the target domain and inference-based methods incorporate adaptation into the parameter estimation procedure, for instance through constraints on the optimization procedure. Additionally, we review a number of conditions that allow for formulating bounds on the cross-domain generalization error. Our categorization highlights recurring ideas and raises questions important to further research.","tags":[],"title":"A review of domain adaptation without target labels","type":"publication"},{"authors":[],"categories":null,"content":"","date":1567069200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567069200,"objectID":"5d3e9a1c3fc6149d2d9156d6a7503d33","permalink":"https://wmkouw.github.io/talk/sequential-domain-adaptive-machine-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/sequential-domain-adaptive-machine-learning/","section":"event","summary":"This poster recaps two collaboration projects I did during my time as Niels Stensen Fellow at the University of Copenhagen. The main point of my proposal was to study \"sequential domain adaptation\". The left column describes an application to \"spatial sequences\", i.e., multi-site biomedical imaging, and the right column describes an application to \"temporal sequences\", i.e. natural language processing over data collected in snapshots over time. The main take-home message from the work in this Fellowship is that domain adaptation is a solution to training machine learning models under sampling bias and that sequential adaptation allows for updating.","tags":["machine-learning","domain-adaptation"],"title":"Sequential domain-adaptive machine learning","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1564444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564444800,"objectID":"30983f85bf22e6ec56706e8ad541c5f0","permalink":"https://wmkouw.github.io/publication/covshift-rob/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/covshift-rob/","section":"publication","summary":"Cross-validation under sample selection bias can, in principle, be done by importance-weighting the empirical risk. However, the importance-weighted risk estimator produces sub-optimal hyperparameter estimates in problem settings where large weights arise with high probability. We study its sampling variance as a function of the training data distribution and introduce a control variate to increase its robustness to problematically large weights.","tags":[],"title":"Robust importance-weighted cross-validation under sample selection bias","type":"publication"},{"authors":[],"categories":null,"content":"","date":1559656800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559656800,"objectID":"4c2ce0735d70ac99a7da109f84f4d040","permalink":"https://wmkouw.github.io/talk/cross-center-smoothness-prior-for-bayesian-image-segmentation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/cross-center-smoothness-prior-for-bayesian-image-segmentation/","section":"event","summary":"MR images vary across medical centers due to calibration and acquisition protocols. But segmentations are relatively consistent. How segmentations are supposed to look like, can be learned separately. We present a smoothness prior that is ﬁt to segmentations from a source medical center. This empirical prior is incorporated into an unsupervised Bayesian image segmentation model. The model clusters voxel intensities in the target center, such that its segmentations are similarly smooth.","tags":["image-segmentation","acquisition-variance","variational-Bayes"],"title":"Cross-center smoothness prior for Bayesian image segmentation","type":"event"},{"authors":[],"categories":null,"content":"","date":1554732000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554732000,"objectID":"162270fea7224cc63f881e95d458e59d","permalink":"https://wmkouw.github.io/talk/mr-acquisition-invariant-representation-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/mr-acquisition-invariant-representation-learning/","section":"event","summary":"Generalization of voxelwise classifiers is hampered by differences between MRI-scanners, e.g., different acquisition protocols and field strengths. We propose a Siamese neural network (MRAI-NET) that extracts acquisition-invariant feature vectors.","tags":["medical-imaging","image-segmentation","acquisition-variance","deep-learning"],"title":"MR acquisition-invariant representation learning","type":"event"},{"authors":["Wouter M. Kouw","Silas Ørting","Jens Petersen","Kim Pedersen","Marleen de Bruijne"],"categories":null,"content":"","date":1551866400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551866400,"objectID":"cee65a9c0fe7901f2f5d12e3a5271303","permalink":"https://wmkouw.github.io/publication/infpp/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/infpp/","section":"publication","summary":"Suppose one is faced with the challenge of tissue segmentation in MR images, without annotators at their center to provide labeled training data. One option is to go to another medical center for a trained classifier. Sadly, tissue classifiers do not generalize well across centers due to voxel intensity shifts caused by center-specific acquisition protocols. However, certain aspects of segmentations, such as spatial smoothness, remain relatively consistent and can be learned separately. Here we present a smoothness prior that is fit to segmentations produced at another medical center. This informative prior is presented to an unsupervised Bayesian model. The model clusters the voxel intensities, such that it produces segmentations that are similarly smooth to those of the other medical center. In addition, the unsupervised Bayesian model is extended to a semi-supervised variant, which needs no visual interpretation of clusters into tissues.","tags":["bayesian-inference","domain-adaptation"],"title":"A cross-center smoothness prior for variational Bayesian brain tissue segmentation","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://wmkouw.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Wouter M. Kouw","Marco Loog","Wilbert Bartels","Adriënne Mendrik"],"categories":null,"content":"","date":1547596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547596800,"objectID":"7ce72db0bdcce40616cdf7a88de7ed1d","permalink":"https://wmkouw.github.io/publication/mrai-net/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/mrai-net/","section":"publication","summary":"Generalization of voxelwise classifiers is hampered by differences between MRI-scanners, e.g. different acquisition protocols and field strengths. To address this limitation, we propose a Siamese neural network (MRAI-NET) that extracts acquisition-invariant feature vectors. These can consequently be used by task-specific methods, such as voxelwise classifiers for tissue segmentation. MRAI-NET is tested on both simulated and real patient data. Experiments show that MRAI-NET outperforms voxelwise classifiers trained on the source or target scanner data when a small number of labeled samples is available.","tags":[],"title":"Learning an MR acquisition-invariant representation using Siamese neural networks","type":"publication"},{"authors":["Jordi Minnema","Maureen van Eijnatten","Wouter M. Kouw","Faruk Diblen","Adriënne Mendrik","Jan Wolff"],"categories":null,"content":" ","date":1543658400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543658400,"objectID":"dd668fa53fd07288995a571652933f64","permalink":"https://wmkouw.github.io/publication/ct-boneseg/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ct-boneseg/","section":"publication","summary":" OBJECTIVES: The most tedious and time-consuming task in medical additive manufacturing (AM) is image segmentation. The aim of the present study was to develop and train a convolutional neural network (CNN) for bone segmentation in computed tomography (CT) scans. METHODS: The CNN was trained with CT scans acquired using six different scanners. Standard tessellation language (STL) models of 20 patients who had previously undergone craniotomy and cranioplasty using additively manufactured skull implants served as 'gold standard' models during CNN training. The CNN segmented all patient CT scans using a leave-2-out cross-validation scheme. All segmented CT scans were converted into STL models and geometrically compared with the gold standard STL models. RESULTS: The CT scans segmented using the CNN demonstrated a large overlap with the gold standard segmentation and resulted in a mean Dice similarity coefficient of 0.92 (0.04). The CNN-based STL models demonstrated mean surface deviations ranging between -0.19 (0.86) mm and 1.22 (1.75) mm, when compared to the gold standard STL models. No major differences were observed between the mean deviations of the CNN-based STL models acquired using six different CT scanners. CONCLUSIONS: The fully-automated CNN was able to accurately segment the skull. CNNs thus offer the opportunity of removing the current prohibitive barriers of time and effort during CT image segmentation, making patient-specific AM constructs more accessible.","tags":[],"title":"CT image segmentation of bone for medical additive manufacturing using a CNN","type":"publication"},{"authors":[],"categories":null,"content":"","date":1536397200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536397200,"objectID":"7aac80f8e6b3d242d3cf6f8b90e25ab7","permalink":"https://wmkouw.github.io/talk/big-data-trust/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/big-data-trust/","section":"event","summary":"Research institutions, hospitals, governments and companies are collecting all kinds of data at an increased rate. Such “big data” offers the possibility to increase our understanding of human behavior, improve clinical diagnosis, and create intelligent consumer products. However, data can also end up in the hands of parties that may take advantage of you. For example, Facebook user data was leaked to political campaigners to influence voters [1]. Central to this debate is the concept of trust: how can you trust that the data that you give out will not end up hurting you?\nThis debate was recently sparked by the adoption of the General Data Protection Regulation (GDPR), which gives individuals in the EU the right to review and destroy personal data collected by third parties. The GDPR greatly complicates the collection and dissemination of research data, particularly in medical sciences. How should researchers analyze data and publish their findings if their subjects decide that their data is to remain private? Can patient data be fully anonymized and yet remain traceable at the same time?  And how does data protection and privacy fit within the principle of open science that encourages researchers to make their data Findable, Accessible, Interoperable, and Reusable (FAIR)?\nAn interesting novel technology in the data and trust debate is blockchain. The goal is to create a distributed transaction system without a central authority that profits from this position, for example the exchange of money without the intervention of a bank. Individual users can issue transactions that are subsequently verified by the entire community through a blockchain. If there’s foul play, for instance by someone changing their own balance, the transaction is rejected by the community. Blockchain thus ensures consensus between users that do not trust each other, which makes the technology interesting for a wide range of applications.\nIn this workshop, we will present different views on how big data is currently being used. Furthermore, we will initiate an interactive discussion with the audience during which the participants can answer questions and share opinions using their smartphones.","tags":["big-data","GDPR"],"title":"Big data \u0026 trust","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1534982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534982400,"objectID":"03cf7624cf50c43e6b48c8b523bfdecd","permalink":"https://wmkouw.github.io/publication/covshift-skew/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/covshift-skew/","section":"publication","summary":"Importance-weighting is a popular and well-researched technique for dealing with sample selection bias and covariate shift. It has desirable characteristics such as unbiasedness, consistency and low computational complexity. However, weighting can have a detrimental effect on an estimator as well. In this work, we empirically show that the sampling distribution of an importance-weighted estimator can be skewed. For sample selection bias settings, and for small sample sizes, the importance-weighted risk estimator produces overestimates for datasets in the body of the sampling distribution, i.e. the majority of cases, and large underestimates for data sets in the tail of the sampling distribution. These over- and underestimates of the risk lead to suboptimal regularization parameters when used for importance-weighted validation.","tags":[],"title":"Effects of sampling skewness of the importance-weighted risk estimator on model selection","type":"publication"},{"authors":[],"categories":null,"content":"","date":1534773600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534773600,"objectID":"5dde694572d8b3c7ed3a6ae104db04a2","permalink":"https://wmkouw.github.io/talk/effects-of-sampling-skewness-in-importance-weighted-cross-validation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/effects-of-sampling-skewness-in-importance-weighted-cross-validation/","section":"event","summary":"I presented my paper on how the importance-weighted risk estimator's sampling distribution is skewed for small sample sizes. The weights effectively ensure an under- or over-estimation of risk, depending on whether the source distribution has larger or smaller variance than the target distribution, respectively. I explore how this affects hyperparameter selection during importance-weighted cross-validation.","tags":["importance-weighting","cross-validation","covariate-shift"],"title":"Effects of sampling skewness in importance-weighted cross-validation","type":"event"},{"authors":null,"categories":null,"content":"The capacity of supervised learning systems to generalize to new examples is inherently limited by the collected data. If it is not an accurate reﬂection of the population, then the system will not perform well. In particular, if the collected data is biased, which means that one observes certain examples more often than normal, then the system can be misled into thinking that certain outcomes are also more likely to occur. Although the system might make accurate diagnoses for new patients arriving to that particular hospital, it will make inaccurate diagnoses for patients arriving to 1a diﬀerent hospital. The diﬀerences between patient populations might be due to regional diﬀerences such as exercise culture, but the fact that one observes for instance older patients more than normal means that data collected from that hospital is biased with respect to the total human population.\nHandling biased samples from populations is a problem that has long been studied in statistics and econometrics. Although a number of techniques have been proposed to improve supervised learning systems trained on biased data, things have changed with the tremendous increase in computational power in the last 20 years. The ﬁeld has advanced to the point where we ask the question whether it is possible to generalize to particular target populations as well. Can we adapt a supervised learning system trained on adult human heart disease patients to make accurate decisions for infant heart disease patients?\nWork from the last 10 years has looked at incorporating unlabeled data from these target populations. With this additional information, systems can recognize changes in data properties, ﬁnd correspondences between populations and adapt their decisions accordingly. Successful adaptation is deﬁned as an improvement over the performance of the original system. Nonetheless, the analysis of this problem is not complete, and it is not clear which conditions have to be fulﬁlled in order for the system to perform well. It seems that in cases where it is diﬃcult to describe how two populations relate to each other, adaptive systems suﬀer from high variability. They are highly uncertain about their decisions and often wrong. However, it seems that the more similar the populations are, the likelier it is that the system adapts well. It would, for example, be easier for the system to adapt to predict heart disease in adolescents based on data from adults, then it would for the system to adapt to infants. However, here might lie a potentially crucial insight: can we design a system that ﬁrst adapts to the closest population and only then adapts to the ﬁnal target population? In other words, a system that sequentially adapts?\nThis position is supported by a Niels Stensen Fellowship grant, offered by the Niels Stensen Stichting.\n","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"cf6989131917c8deb50651bc41059b38","permalink":"https://wmkouw.github.io/project/seqdais/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/project/seqdais/","section":"project","summary":"Sequential Domain Adaptive Intelligent Systems focuses on domain-adaptative classification over an ordered sequence of biased samples. An example of such a sequence is medical data from hospital along a geographic path.","tags":["domain-adaptation","machine-learning"],"title":"SeqDAIS","type":"project"},{"authors":[],"categories":null,"content":"","date":1525863600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525863600,"objectID":"7b66d7e23ad3c2880f4e79e9e986acba","permalink":"https://wmkouw.github.io/talk/mr-acquisition-invariant-representation-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/mr-acquisition-invariant-representation-learning/","section":"event","summary":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on removing MRI-scanner based varation from images.","tags":["domain-adaptation","neural-networks","mri"],"title":"MR acquisition-invariant representation learning","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1493510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493510400,"objectID":"eb727c4c6badaf8b438960a1fff4e2b6","permalink":"https://wmkouw.github.io/publication/tr-introda/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/tr-introda/","section":"publication","summary":"In machine learning, if the training data is an unbiased sample of an underlying distribution, then the learned classification function will make accurate predictions for new samples. However, if the training data is _not_ an unbiased sample, then there will be differences between how the training data is distributed and how the test data is distributed. Standard classifiers cannot cope with changes in data distributions between training and test phases, and will not perform well. _Domain_ _adaptation_ and _transfer_ _learning_ are sub-fields within machine learning that are concerned with accounting for these types of changes. Here, I present an introduction to these fields, guided by the question: when and how can a classifier generalize from a source to a target domain? I will start with a brief introduction into risk minimization, and how transfer learning and domain adaptation expand upon this framework. Following that, I discuss three common simple data set shifts, namely prior, covariate and concept shift. For more complex domain shifts, there are a wide variety of approaches. These are categorized into: importance-weighting, subspace mapping, domain-invariant projections, feature augmentation, minimax estimators and robust algorithms. A number of points will arise, which I will discuss in the last section. I conclude with the remark that many open questions will have to be addressed before transfer learners and domain-adaptive classifiers become practical.","tags":[],"title":"An introduction to domain adaptation and transfer learning","type":"publication"},{"authors":[],"categories":null,"content":"","date":1489075200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489075200,"objectID":"0798e491f1205bd98610c050856b910d","permalink":"https://wmkouw.github.io/talk/variance-reduction-techniques-for-importance-weighted-cross-validation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/variance-reduction-techniques-for-importance-weighted-cross-validation/","section":"event","summary":"One can often not evaluate a classiﬁer in the target domain due to the absence of target labels. Fortunately, in the covariate shift setting, the target risk equals the importance-weighted source risk. However, depending on the domain dissimilarity, the variance of the importance weights can drastically increase the variance of the risk estimator. Here we introduce a control variate to reduce the sampling variance of the importance-weighted risk estimator.","tags":["machine-learning","covariate-shift","importance-weighting"],"title":"Variance reduction techniques for importance-weighted cross-validation","type":"event"},{"authors":[],"categories":null,"content":"","date":1481378400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481378400,"objectID":"e67f76e62b3e3dbff909d979d81af362","permalink":"https://wmkouw.github.io/talk/on-cross-validation-under-covariate-shift/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/on-cross-validation-under-covariate-shift/","section":"event","summary":"I presented my paper on problems with importance-weighted cross-validation under covariate shift. Under covariate shift, the standard cross-validation estimator is not consistent (i.e. it won't return optimal hyperparameter estimates). Importance-weighting the cross-validation estimator was deemed to resolve this issue, but we show that it is still not consistent.","tags":["cross-validation","covariate-shift","domain-adaptation"],"title":"On cross-validation under covariate shift","type":"event"},{"authors":["Wouter M. Kouw","Marco Loog"],"categories":null,"content":" ","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"66c99b844a68037323432089a6566ff6","permalink":"https://wmkouw.github.io/publication/covshift-reg/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/covshift-reg/","section":"publication","summary":"This paper identifies a problem with the usual procedure for L2-regularization parameter estimation in a domain adaptation setting. In such a setting, there are differences between the distributions generating the training data (source domain) and the test data (target domain). The usual cross-validation procedure requires validation data, which can not be obtained from the unlabeled target data. The problem is that if one decides to use source validation data, the regularization parameter is underestimated. One possible solution is to scale the source validation data through importance weighting, but we show that this correction is not sufficient. We conclude the paper with an empirical analysis of the effect of several importance weight estimators on the estimation of the regularization parameter.","tags":[],"title":"On regularization parameter estimation under covariate shift","type":"publication"},{"authors":["Wouter M. Kouw","Laurens van der Maaten","Jesse Krijthe","Marco Loog"],"categories":null,"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"f0bf06f5c95d069a5cebe54a0b866076","permalink":"https://wmkouw.github.io/publication/flda/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/flda/","section":"publication","summary":"Domain adaptation has become a prominent problem setting in machine learning and related fields. This review asks the question: how can a classifier learn from a source domain and generalize to a target domain? We present a categorization of approaches, divided into, what we refer to as, sample-based, feature-based and inference-based methods. Sample-based methods focus on weighting individual observations during training based on their importance to the target domain. Feature-based methods revolve around on mapping, projecting and representing features such that a source classifier performs well on the target domain and inference-based methods incorporate adaptation into the parameter estimation procedure, for instance through constraints on the optimization procedure. Additionally, we review a number of conditions that allow for formulating bounds on the cross-domain generalization error. Our categorization highlights recurring ideas and raises questions important to further research.","tags":[],"title":"Feature-level domain adaptation","type":"publication"},{"authors":[],"categories":null,"content":"","date":1464361200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464361200,"objectID":"b0dc9ca1eb1ef5d81017f10c3996a8d6","permalink":"https://wmkouw.github.io/talk/target-contrastive-estimator-for-robust-domain-adaptation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/target-contrastive-estimator-for-robust-domain-adaptation/","section":"event","summary":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on a robust estimator for linear discriminant analysis in domain-adaptive machine learning.","tags":["machine-learning","domain-adaptation"],"title":"Target contrastive estimator for robust domain adaptation","type":"event"},{"authors":[],"categories":null,"content":"","date":1458468000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458468000,"objectID":"a586c9d0ea566c065f79e876ee841e7d","permalink":"https://wmkouw.github.io/talk/feature-level-domain-adaptation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/feature-level-domain-adaptation/","section":"event","summary":"Importance-weighting is a popular and well-researched technique for dealing with sample selection bias and covariate shift. It has desirable characteristics such as unbiasedness, consistency and low computational complexity. However, weighting can have a detrimental effect on an estimator as well. In this work, we empirically show that the sampling distribution of an importance-weighted estimator can be skewed. For sample selection bias settings, and for small sample sizes, the importance-weighted risk estimator produces overestimates for data sets in the body of the sampling distribution, i.e. the majority of cases, and large underestimates for data sets in the tail of the sampling distribution. These over- and underestimates of the risk lead to sub-optimal regularization parameters when used for importance-weighted validation.","tags":["machine-learning","domain-adaptation"],"title":"Feature-level domain adaptation","type":"event"},{"authors":[],"categories":null,"content":"","date":1426608000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1426608000,"objectID":"7b48616b0a0a34275bb6b9ff17da5c49","permalink":"https://wmkouw.github.io/talk/feature-absence-regularization-for-domain-adaptive-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/feature-absence-regularization-for-domain-adaptive-learning/","section":"event","summary":"SNN organized a one day symposium entitled Intelligent Machines, where an overview of recent developments was presented. The meeting aimed to establish a dialogue and to build connections between academic research, industry and public institutions in the Netherlands. I presented my preliminary work on incorporating transfer models in domain-adaptive classifiers.","tags":["machine-learning","domain-adaptation"],"title":"Feature absence regularization for domain-adaptive learning","type":"event"},{"authors":null,"categories":null,"content":"Artificial intelligence, in particular machine learning and pattern recognition, is concerned with teaching computer systems to perform tasks. Tasks such as autonomous driving, recognizing tumors in medical images, or detecting suspicious packages in airports. Such systems learn by observing examples, i.e. data, and forming a mathematical description of what types of variations occur, i.e. a statistical model. For new input, the system computes the most likely output and makes a decision accordingly. As a scientific field, it is situated between statistics and and algorithmics. As a technology, it has become a very powerful tool due to the massive amounts of data being collected and the drop in the cost of computation.\nHowever, obtaining enough data is still very difficult. There are often substantial financial, operational or ethical considerations in collecting data. The majority of research in machine learning deals with constraints on the amount, the labeling and the types of data that are available. One such constraint is that it is only possible to collect labeled data from one population, or domain, but the goal is to make decisions for another domain. It is unclear under which conditions this will be possible, which inspires the research question: when and how can a classification algorithm generalize from a source domain to a target domain?\nMy research has looked at different approaches to domain adaptation. Firstly, we have asked some critical questions on whether the standard approaches to model validation still hold in the context of different domains. As a result, we have proposed a means to reduce uncertainty in the validation risk estimator, but that does not solve the problem completely. Secondly, we modeled the transfer from source to target domain using parametric families of distributions, which works well in simple contexts such as feature dropout at test time. Thirdly, we looked at a more practical problem: tissue classifiers trained on data from one MRI scanner degrade when applied to data from another scanner due to acquisition-based variations. We tackled this problem by learning a representation for which detrimental variations are minimized while maintaining tissue contrast. Finally, considering that many approaches fail in practice because their assumptions are not met, we designed a parameter estimator that never performs worse than the naive non-adaptive classifier.\n","date":1409529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409529600,"objectID":"6c5f0a78251ba78a7e451df82624aed0","permalink":"https://wmkouw.github.io/project/dapr/","publishdate":"2014-09-01T00:00:00Z","relpermalink":"/project/dapr/","section":"project","summary":"Domain Adaptive Pattern Recognition explores the limits of generalization for a special case of statistical learning where training data and test data are differently biased samples of some underlying data-generating distribution.","tags":["domain-adaptation","transfer-learning","machine-learning","pattern-recognition"],"title":"DAPR","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://wmkouw.github.io/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/","section":"","summary":"","tags":null,"title":"","type":"page"}]