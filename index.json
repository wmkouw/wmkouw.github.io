[{"authors":["W.M. Kouw"],"categories":null,"content":"","date":1594807200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594807200,"objectID":"648dbcf04fd6263ed01063d9b6819f1b","permalink":"https://wmkouw.github.io/publication/nsi-silverbox/","publishdate":"2020-07-15T12:00:00+02:00","relpermalink":"/publication/nsi-silverbox/","section":"publication","summary":"Online system identification is the estimation of parameters of a dynamical system, such as mass or friction coefficients, at each measurement of the input and output signals. Here, we cast the nonlinear stochastic differential equation of a Duffing oscillator to a generative model and infer dynamical parameters using variational message passing on a factor graph of the model. We validate the approach with a forecasting experiment on data from an electronic implementation of a Duffing oscillator.","tags":["system-identification","free-energy-minimisation","bayesian-filtering"],"title":"Online system identification in a Duffing oscillator by free energy minimisation","type":"publication"},{"authors":["A. Podusenko","W.M. Kouw","B. de Vries"],"categories":null,"content":"","date":1592733600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592733600,"objectID":"6ed3f842aa7e36ff14d62bb7944d0437","permalink":"https://wmkouw.github.io/publication/vmphar/","publishdate":"2020-06-21T12:00:00+02:00","relpermalink":"/publication/vmphar/","section":"publication","summary":"Hierarchical autoregressive (AR) models can describe many complex physical processes. Unfortunately, online adaptation in these models under non-stationary conditions remains a challenge. In this paper, we track states and parameters in a hierarchical AR filter by means of variational message passing (VMP) in a factor graph. We derive VMP update rules for an \"AR node\" that can be re-used at various hierarchical levels and supports automated message passing-based inference for states and parameters. The proposed method is experimentally validated for a 2-level hierarchical AR model.","tags":["bayesian-filtering","autoregression"],"title":"Online variational message passing in hierarchical autoregressive models","type":"publication"},{"authors":null,"categories":null,"content":"\nWe address the problem of online Bayesian state and parameter tracking in autoregressive (AR) models with time-varying process noise variance. The involved marginalization and expectation integrals cannot be analytically solved. Moreover, the online tracking constraint makes sampling and batch learning methods unsuitable for this problem. We propose a hybrid variational message passing algorithm that robustly tracks the time-varying dynamics of the latent states, AR coefficients and process noise variance. Since message passing in a factor graph is a highly modular inference approach, the proposed methods easily extend to other non-stationary dynamic modeling problems.\n","date":1591878401,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591878401,"objectID":"2b59ccef5f35a8c194da478cf7398163","permalink":"https://wmkouw.github.io/project/ar-hgf/","publishdate":"2020-06-11T13:26:41+01:00","relpermalink":"/project/ar-hgf/","section":"project","summary":"Online inference for an autoregressive process with time-varying variance.","tags":[],"title":"AR-HGF","type":"project"},{"authors":["I. Senoz","A. Podusenko","W.M. Kouw","B. de Vries"],"categories":null,"content":"","date":1591873200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591873200,"objectID":"fae4217ea429178e32e0a75dc9bba222","permalink":"https://wmkouw.github.io/publication/vmpar-hgf/","publishdate":"2020-06-11T12:00:00+01:00","relpermalink":"/publication/vmpar-hgf/","section":"publication","summary":"We address the problem of online Bayesian state and parameter tracking in autoregressive (AR) models with time-varying process noise variance. The involved marginalization and expectation integrals cannot be analytically solved. Moreover, the online tracking constraint makes sampling and batch learning methods unsuitable for this problem. We propose a hybrid variational message passing algorithm that robustly tracks the time-varying dynamics of the latent states, AR coefficients and process noise variance. Since message passing in a factor graph is a highly modular inference approach, the proposed methods easily extend to other non-stationary dynamic modeling problems.","tags":["bayesian-filtering","autoregression","hierarchical-gaussian-filter"],"title":"Bayesian joint state and parameter tracking in autoregressive models","type":"publication"},{"authors":null,"categories":null,"content":"In Bayesian filtering, states and parameters of probabilistic state-space models are inferred in an online manner. Using the Free Energy Principle, the state-space model is cast to a generative model p and the posterior distributions of interest are approximated using recognition distributions or beliefs q. The factorisation of state-space models into state transitions and observation likelihoods over time supports forming a factor graph and performing inference via message passing.\nTools for message passing on factor graphs typically employ a scheduling procedure, in which a separate algorithm or compiler takes the model description and returns which nodes should pass messages where at what time. This can be sufficiently expensive to form a bottleneck. Moreover, it\u0026rsquo;s not a biologically plausible mechanism for governing message passing. I explore the possibility of passing messages without a scheduler. A designated terminal node should pass an initial message, which will arrive at an initial variable. The corresponding belief is updated, a local Free Energy is computed and the belief is emitted to neighbouring factor nodes. From there on out, whenever an updated belief arrives at a factor node, the node fires messages to all other variables if the local Free Energy surpasses a threshold. If not, the node becomes silent.\n","date":1585648800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585648800,"objectID":"99615480d83785c55607079d128b06ab","permalink":"https://wmkouw.github.io/talk/neuromatch2020/","publishdate":"2020-03-31T12:00:00+02:00","relpermalink":"/talk/neuromatch2020/","section":"talk","summary":"In Bayesian filtering, states and parameters of probabilistic state-space models are inferred in an online manner. Using the Free Energy Principle, the state-space model is cast to a generative model p and the posterior distributions of interest are approximated using recognition distributions or beliefs q. The factorisation of state-space models into state transitions and observation likelihoods over time supports forming a factor graph and performing inference via message passing.\nTools for message passing on factor graphs typically employ a scheduling procedure, in which a separate algorithm or compiler takes the model description and returns which nodes should pass messages where at what time.","tags":["variational Bayesian inference","Bayesian filtering","schedule-free message-passing"],"title":"Schedule-free variational message passing for Bayesian filtering","type":"talk"},{"authors":["E. Hart","R. van de Schoot","W.M. Kouw","D. Veen","A.M. Mendrik"],"categories":null,"content":"","date":1582795276,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582795276,"objectID":"f04b97dd76992f7eff85732f396feeb3","permalink":"https://wmkouw.github.io/publication/drc/","publishdate":"2020-02-27T10:21:16+01:00","relpermalink":"/publication/drc/","section":"publication","summary":"In a broad range of fields it may be desirable to reuse a supervised classification algorithm and apply it to a new data set. However, generalization of such an algorithm and thus achieving a similar classification performance is only possible when the training data used to build the algorithm is similar to new unseen data one wishes to apply it to. It is often unknown in advance how an algorithm will perform on new unseen data, being a crucial reason for not deploying an algorithm at all. Therefore, tools are needed to measure the similarity of data sets. In this paper, we propose the Data Representativeness Criterion (DRC) to determine how representative a training data set is of a new unseen data set. We present a proof of principle, to see whether the DRC can quantify the similarity of data sets and whether the DRC relates to the performance of a supervised classification algorithm. We compared a number of magnetic resonance imaging (MRI) data sets, ranging from subtle to severe difference is acquisition parameters. Results indicate that, based on the similarity of data sets, the DRC is able to give an indication as to when the performance of a supervised classifier decreases. The strictness of the DRC can be set by the user, depending on what one considers to be an acceptable underperformance.","tags":["domain-adaptation","transfer-learning"],"title":"The data representativeness criterion","type":"publication"},{"authors":null,"categories":null,"content":"Bayesian Machine Learning \u0026amp; Information Processing (BMLIP) is an elective course in the Electrical Engineering Master Program of the TU Eindhoven.\nBMLIP covers the fundamentals of the Bayesian (i.e., probabilistic) approach to machine learning and information processing systems. Firstly, we discuss many useful models including common regression and classification methods, Gaussian mixture models, hidden Markov models and Kalman filters. Secondly, we teach Expectation-Maximization (EM), Variational Bayes (VB), Variational Message Passing (VMP) and basic Monte Carlo sampling. Lastly, we discuss intelligent agents that learn purposeful behavior from interactions with their environment.\nI teach the mini-course on Probabilistic Programming, where we familiarize students with software for automatic inference in probabilistic models.\n","date":1579177601,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579177601,"objectID":"51bcedd423f97b37d167b1642e658b29","permalink":"https://wmkouw.github.io/teaching/tue-5ssd0/","publishdate":"2020-01-16T13:26:41+01:00","relpermalink":"/teaching/tue-5ssd0/","section":"teaching","summary":"Bayesian Machine Learning \u0026 Information Processing","tags":[],"title":"TUe 5SSD0 BMLIP","type":"teaching"},{"authors":null,"categories":null,"content":"\nLanguage evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens \u0026lsquo;BERT\u0026rsquo; and \u0026lsquo;ELMO\u0026rsquo; in publications refer to neural network architectures rather than persons [1, 2]. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences (regular intervals) or author stance prediction for rumours on Twitter (irregular intervals). We tackle data drift by sequentially aligning learned representations. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution.\n","date":1573820801,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573820801,"objectID":"34beb74e7c7beb588d7a011808b6b616","permalink":"https://wmkouw.github.io/project/ssa-nlp/","publishdate":"2019-11-15T13:26:41+01:00","relpermalink":"/project/ssa-nlp/","section":"project","summary":"Sequential subspace alignment for temporal drifts in language usage.","tags":[],"title":"SSA-NLP","type":"project"},{"authors":["J. Bjerva","W.M. Kouw","I. Augenstein"],"categories":null,"content":"","date":1573448440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573448440,"objectID":"11be9c2e500a676738303621d7c36a06","permalink":"https://wmkouw.github.io/publication/seqrum/","publishdate":"2019-11-11T06:00:40+01:00","relpermalink":"/publication/seqrum/","section":"publication","summary":"Language evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO' in publications refer to neural network architectures rather than persons. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences (regular intervals) or author stance prediction for rumours on Twitter (irregular intervals). Inspired by successes in computer vision, we tackle data drift by sequentially aligning learned representations. %We consider both unsupervised and semi-supervised alignment. We evaluate on three challenging tasks varying in terms of time-scales, linguistic units, and domains. These tasks show our method outperforming several strong baselines, including using all available data. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution.","tags":["natural-language-processing","domain-adaptation","temporal-drift","subspace-alignment"],"title":"Back to the future - sequential alignment of text representations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1570777903,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570777903,"objectID":"542c2598c9cff3d602dbedfb6c97d879","permalink":"https://wmkouw.github.io/talk/mlsp2019/","publishdate":"2019-10-11T09:11:43+02:00","relpermalink":"/talk/mlsp2019/","section":"talk","summary":"","tags":["importance-weighting","cross-validation","sample-selection-bias"],"title":"Robust importance-weighted cross-validation under sample selection bias","type":"talk"},{"authors":["W.M. Kouw","M. Loog"],"categories":null,"content":"","date":1570457639,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570457639,"objectID":"1895a75cd101c0cd929281f5f1e5d39e","permalink":"https://wmkouw.github.io/publication/review/","publishdate":"2019-10-07T16:13:59+02:00","relpermalink":"/publication/review/","section":"publication","summary":"Domain adaptation has become a prominent problem setting in machine learning and related fields. This review asks the question: how can a classifier learn from a source domain and generalize to a target domain? We present a categorization of approaches, divided into, what we refer to as, sample-based, feature-based and inference-based methods. Sample-based methods focus on weighting individual observations during training based on their importance to the target domain. Feature-based methods revolve around on mapping, projecting and representing features such that a source classifier performs well on the target domain and inference-based methods incorporate adaptation into the parameter estimation procedure, for instance through constraints on the optimization procedure. Additionally, we review a number of conditions that allow for formulating bounds on the cross-domain generalization error. Our categorization highlights recurring ideas and raises questions important to further research.","tags":["machine-learning","domain-adaptation","transfer-learning","covariate-shift","sample-selection-bias"],"title":"A review of domain adaptation without target labels","type":"publication"},{"authors":null,"categories":null,"content":"This poster recaps two collaboration projects I did during my time as Niels Stensen Fellow at the University of Copenhagen. The main point of my proposal was to study \u0026ldquo;sequential domain adaptation\u0026rdquo;. The left column describes an application to \u0026ldquo;spatial sequences\u0026rdquo;, i.e., multi-site biomedical imaging, and the right column describes an application to \u0026ldquo;temporal sequences\u0026rdquo;, i.e. natural language processing over data collected in snapshots over time. The main take-home message from the work in this Fellowship is that domain adaptation is a solution to training machine learning models under sampling bias and that sequential adaptation allows for updating.\n","date":1567033200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567033200,"objectID":"584aa700db05d9f612e80c2db2c0cc8f","permalink":"https://wmkouw.github.io/talk/nsf2019/","publishdate":"2019-08-29T00:00:00+01:00","relpermalink":"/talk/nsf2019/","section":"talk","summary":"This poster recaps two collaboration projects I did during my time as Niels Stensen Fellow at the University of Copenhagen. The main point of my proposal was to study \u0026ldquo;sequential domain adaptation\u0026rdquo;. The left column describes an application to \u0026ldquo;spatial sequences\u0026rdquo;, i.e., multi-site biomedical imaging, and the right column describes an application to \u0026ldquo;temporal sequences\u0026rdquo;, i.e. natural language processing over data collected in snapshots over time. The main take-home message from the work in this Fellowship is that domain adaptation is a solution to training machine learning models under sampling bias and that sequential adaptation allows for updating.","tags":["domain-adaptation","machine-learning"],"title":"Sequential domain-adaptive machine learning","type":"talk"},{"authors":["W.M. Kouw","J.H. Krijthe","M. Loog"],"categories":null,"content":"","date":1564464864,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564464864,"objectID":"63c2c041591a94bb0a954bddd147fc4d","permalink":"https://wmkouw.github.io/publication/robust-iwxval/","publishdate":"2019-07-30T06:34:24+01:00","relpermalink":"/publication/robust-iwxval/","section":"publication","summary":"Cross-validation under sample selection bias can, in principle, be done by importance-weighting the empirical risk. However, the importance-weighted risk estimator produces sub-optimal hyperparameter estimates in problem settings where large weights arise with high probability. We study its sampling variance as a function of the training data distribution and introduce a control variate to increase its robustness to problematically large weights.  ","tags":["cross-validation","covariate-shift","sample-selection-bias","control-variate"],"title":"Robust importance-weighted cross-validation under sample selection bias","type":"publication"},{"authors":null,"categories":null,"content":"A simple idea: learn how smooth medical image segmentations are supposed to look like and use this knowledge as a prior for Bayesian image segmentation. That way, you avoid learning a different mapping from scan to segmentation for each scanner while still learning from data at other medical centers.\n","date":1559459503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559459503,"objectID":"49d2b8fb6ed8ab257334ba5f62e2956d","permalink":"https://wmkouw.github.io/talk/ipmi2019/","publishdate":"2019-06-02T09:11:43+02:00","relpermalink":"/talk/ipmi2019/","section":"talk","summary":"A simple idea: learn how smooth medical image segmentations are supposed to look like and use this knowledge as a prior for Bayesian image segmentation. That way, you avoid learning a different mapping from scan to segmentation for each scanner while still learning from data at other medical centers.","tags":["image-segmentation","acquisition-variance","variational-Bayes"],"title":"Cross-center smoothness prior for Bayesian image segmentation","type":"talk"},{"authors":[],"categories":[],"content":"On many occasions, I have seen researchers being recommended to work on practical problems. For example, instead of looking for a neural network architecture that has never been proposed before, design a model for tracking a particular stage of cancer development. A first argument is that this makes a stronger impact on clinical research and society. The applied researcher would be happy, but a theorist would argue that the result is too specific to generalize to other diseases, and is therefore less interesting. But new problem settings can reveal new behavior of a model or method. Therefore, it is also in the interest of the theorist to consider practical problems.\nBut I argue that not all practical problems are interesting. Some exist purely because people cannot communicate well or agree on something. An example is the use of different protocols: suppose there are two teams working on genomic data analysis [1]. Both use different protocols, because each thinks theirs is better (which is probably true since both define different metrics). Although each team produces excellent work, their data sets cannot be easily integrated due to the differences in protocol. Without large cross-center data sets, it becomes difficult to fit more complex models, and answer more difficult questions.\nThe analyst is often tasked with automatically integrating data sets, or designing models that cope with a variety of data sets. The frustrating thing is that this task is unnecessary; it would be resolved if both teams would use coherent protocols. Certain bodies of government are aware of this, such as the EU, but it is proving difficult to convince people to adhere to a policy [2].\nPractical problems are not always interesting: some reveal more about people and their choices, than about the behavior of a model or method.\nReferences: [1] Tackling the widespread and critical impact of batch effects in high-throughput data. Leek et al., Nature Reviews, 2010.\n[2] Turning FAIR into reality: Final report and action plan from the European Commission expert group on FAIR data. Directorate-General for Research and Innovation (European Commission), EU publications, 2018.\n","date":1558537097,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558537097,"objectID":"c1ae207156d3c4b83ee73fbeeeb32a3b","permalink":"https://wmkouw.github.io/post/practical_problems/","publishdate":"2019-05-22T16:58:17+02:00","relpermalink":"/post/practical_problems/","section":"post","summary":"On many occasions, I have seen researchers being recommended to work on practical problems. For example, instead of looking for a neural network architecture that has never been proposed before, design a model for tracking a particular stage of cancer development. A first argument is that this makes a stronger impact on clinical research and society. The applied researcher would be happy, but a theorist would argue that the result is too specific to generalize to other diseases, and is therefore less interesting.","tags":[],"title":"Are all practical problems interesting?","type":"post"},{"authors":null,"categories":null,"content":"This conference poster refers back to the project on accounting for variation in medical images due to MR acquisition protocol. Acquisition variation is caused by different vendors, mechanical calibrations and environmental effects at different medical centers, and hamper generalization of medical image processing techniques that employ machine learning.\n","date":1555053103,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555053103,"objectID":"74e609a7841c0a943e6448e3141e2264","permalink":"https://wmkouw.github.io/talk/isbi2019/","publishdate":"2019-04-12T09:11:43+02:00","relpermalink":"/talk/isbi2019/","section":"talk","summary":"This conference poster refers back to the project on accounting for variation in medical images due to MR acquisition protocol. Acquisition variation is caused by different vendors, mechanical calibrations and environmental effects at different medical centers, and hamper generalization of medical image processing techniques that employ machine learning.","tags":["medical-imaging","image-segmentation","acquisition-variance","deep-learning"],"title":"MR Acquisition-invariant representation learning","type":"talk"},{"authors":null,"categories":null,"content":"\nForneyLab.jl is a Julia package for automatic generation of (Bayesian) inference algorithms. Given a probabilistic model, ForneyLab generates efficient Julia code for message-passing based inference [1]. It uses the model structure to generate an algorithm that consists of a sequence of local computations on a Forney-style factor graph (FFG) representation of the model [2].\nMarco Cox, Thijs van de Laar en Bert de Vries are the ones who constructed ForneyLab. At the moment, I contribute to the package through support with numerical stability, ease-of-use, and documentation. In the future, I will be adding functionality.\n","date":1551951996,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551951996,"objectID":"f1f81055454c47888e3e9fd11042b893","permalink":"https://wmkouw.github.io/project/forneylab/","publishdate":"2019-03-07T10:46:36+01:00","relpermalink":"/project/forneylab/","section":"project","summary":"Variational message passing on Forney-style factor graphs.","tags":[],"title":"ForneyLab.jl","type":"project"},{"authors":["W.M. Kouw","S.N. Ørting","J. Petersen","K.S. Pedersen","M. de Bruijne"],"categories":null,"content":"","date":1551878012,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551878012,"objectID":"cf7ca57ffdc5c6fc3542592e51988687","permalink":"https://wmkouw.github.io/publication/infoprior/","publishdate":"2019-03-06T14:13:32+01:00","relpermalink":"/publication/infoprior/","section":"publication","summary":"Suppose one is faced with the challenge of tissue segmentation in MR images, without annotators at their center to provide labeled training data. One option is to go to another medical center for a trained classifier. Sadly, tissue classifiers do not generalize well across centers due to voxel intensity shifts caused by center-specific acquisition protocols. However, certain aspects of segmentations, such as spatial smoothness, remain relatively consistent and can be learned separately. Here we present a smoothness prior that is fit to segmentations produced at another medical center. This informative prior is presented to an unsupervised Bayesian model. The model clusters the voxel intensities, such that it produces segmentations that are similarly smooth to those of the other medical center. In addition, the unsupervised Bayesian model is extended to a semi-supervised variant, which needs no visual interpretation of clusters into tissues.","tags":["medical-imaging","variational-Bayes","image-segmentation","acquisition-variation"],"title":"A cross-center smoothness prior for variational Bayesian brain tissue segmentation","type":"publication"},{"authors":null,"categories":null,"content":"\nGeneralizing machine learning algorithms across medical centers is difficult. Data is often strongly biased towards each center, leading to different mappings from medical image X to segmented image Y [1].\nInstead of designing an adaptive classification model that would attempt to adjust its mapping X → Y for each center, I inform an unsupervised Bayesian segmentation model with how Y is supposed to look like. Specifically, I fit a smoothness prior on segmentations produced in one medical center and incorporate that as an informative empirical prior in a variational Bayesian image segmentation model [2]. This model will produce segmentations in a target medical center that are as smooth as the segmentations produced in the source medical center.\n","date":1551472102,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551472102,"objectID":"09fc1be3eac4c9482bad59ef0bc9505a","permalink":"https://wmkouw.github.io/project/info-prior/","publishdate":"2019-03-01T22:28:22+02:00","relpermalink":"/project/info-prior/","section":"project","summary":"Cross-center smoothness prior for variational Bayesian image segmentation.","tags":[],"title":"CC-Priors","type":"project"},{"authors":["Wouter M. Kouw"],"categories":[],"content":"Intelligent systems are deployed for a wide array of tasks, such as diagnosing patients, recognizing faces or translating texts [1]. They are called \u0026ldquo;intelligent\u0026rdquo; because these machines are not specifically programmed to perform the task. Instead, they learn to do their job from a \u0026ldquo;training set\u0026rdquo; of examples. For example, the system might be told to diagnose heart disease in patients based on biometrics such as age and cholesterol level. These biometrics vary across people and there is no fixed rule to form a diagnosis (e.g. \u0026ldquo;if older than 50 and cholesterol over 400, then patient is sick\u0026rdquo;). But, given enough examples of previous patients, the system can estimate the risk of heart disease. The success of these types of systems has been stunning, mostly due to large-scale data collection efforts.\nThe design of intelligent systems is based on statistical learning theory. A statistical classification model, or classifier, will find a function to relate the biometrics in the examples to their diagnosis [2]. Each example, e.g. a healthy patient with a cholesterol level of 300, is a sample from an underlying probability distribution over possible levels of cholesterol in healthy or diseased patients. As the model sees more examples, it gets a better idea of what values are normal for healthy patients and what levels are to be expected for patients with heart disease. As such, it refines its function relating biometrics and diagnosis. We say that a model generalizes when it can accurately classify new examples.\nMost of what is known on generalization is based on the premise that new examples are drawn from the same distribution as the training examples. However, that is not always the case. For example, suppose you measure age and cholesterol in two groups of patients at a particular hospital. One with and without cardiac problems. The figure below visualizes such a dataset with a scatterplot:\nYou now fit a classifier and validate the model on new patients arriving to the hospital. The system works well and people are happy. Doctors from the US hear of your work and ask if they can use your model in their hospital. Sure, you say, and help them deploy it. However, it doesn\u0026rsquo;t work so well in the other hospital. What\u0026rsquo;s going on?\nAs the scatterplot above shows, the patients from the other hospital are - on average - older. The system has been finely attuned to precise values of age and cholesterol, and will subsequently think that nearly all of the new patients are sick. The model is not designed to handle the shift in the data and will perform sub-optimally.\nThese types of learning settings are called domain adaptation problems [3], where one hospital is the target \u0026ldquo;domain\u0026rdquo; and the other hospital is an additional source of information, called the \u0026ldquo;source domain\u0026rdquo;. The goal of a \u0026ldquo;domain-adaptive\u0026rdquo; classifier is to learn from the source domain and \u0026ldquo;adapt\u0026rdquo; to perform well in the target domain. As machine learning faces more complicated challenges, data shifts become more abundant and the need for adaptive models rises.\nReferences\n[1] The rise of computer-aided explanation. Nielsen, Quanta Magazine, 2015. [2] Supervised classification: Quite a brief overview. Loog, Machine Learning Techniques for Space Weather, 2018. [3] An introduction to domain adaptation and transfer learning. Kouw \u0026amp; Loog, Tech Report TU Delft, 2018.\n","date":1549019957,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549019957,"objectID":"03708e666e25ee585d4fdfd2c0bed8a5","permalink":"https://wmkouw.github.io/post/domain_adaptation/","publishdate":"2019-02-01T12:19:17+01:00","relpermalink":"/post/domain_adaptation/","section":"post","summary":"Intelligent systems are deployed for a wide array of tasks, such as diagnosing patients, recognizing faces or translating texts [1]. They are called \u0026ldquo;intelligent\u0026rdquo; because these machines are not specifically programmed to perform the task. Instead, they learn to do their job from a \u0026ldquo;training set\u0026rdquo; of examples. For example, the system might be told to diagnose heart disease in patients based on biometrics such as age and cholesterol level. These biometrics vary across people and there is no fixed rule to form a diagnosis (e.","tags":[],"title":"What is domain-adaptive machine learning?","type":"post"},{"authors":["W.M. Kouw, M. Loog, L.W. Bartels, A.M. Mendrik"],"categories":null,"content":"","date":1547589602,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547589602,"objectID":"515350e69b50ecab6835070f81b623a8","permalink":"https://wmkouw.github.io/publication/mrainet/","publishdate":"2019-01-16T00:00:02+02:00","relpermalink":"/publication/mrainet/","section":"publication","summary":"Generalization of voxelwise classifiers is hampered by differences between MRI-scanners, e.g. different acquisition protocols and field strengths. To address this limitation, we propose a Siamese neural network (MRAI-NET) that extracts acquisition-invariant feature vectors. These can consequently be used by task-specific methods, such as voxelwise classifiers for tissue segmentation. MRAI-NET is tested on both simulated and real patient data. Experiments show that MRAI-NET outperforms voxelwise classifiers trained on the source or target scanner data when a small number of labeled samples is available.","tags":["medical-imaging","image-segmentation","acquisition-variance","deep-learning"],"title":"Learning an MR acquisition-invariant representation using Siamese neural networks","type":"publication"},{"authors":["W.M. Kouw","M. Loog"],"categories":null,"content":"","date":1546263966,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546263966,"objectID":"30d612eead3dfdfa611ac598569d8dc1","permalink":"https://wmkouw.github.io/publication/tr_introda/","publishdate":"2018-12-31T14:46:06+01:00","relpermalink":"/publication/tr_introda/","section":"publication","summary":"In machine learning, if the training data is an unbiased sample of an underlying distribution, then the learned classification function will make accurate predictions for new samples. However, if the training data is _not_ an unbiased sample, then there will be differences between how the training data is distributed and how the test data is distributed. Standard classifiers cannot cope with changes in data distributions between training and test phases, and will not perform well. _Domain_ _adaptation_ and _transfer_ _learning_ are sub-fields within machine learning that are concerned with accounting for these types of changes. Here, I present an introduction to these fields, guided by the question: when and how can a classifier generalize from a source to a target domain? I will start with a brief introduction into risk minimization, and how transfer learning and domain adaptation expand upon this framework. Following that, I discuss three common simple data set shifts, namely prior, covariate and concept shift. For more complex domain shifts, there are a wide variety of approaches. These are categorized into: importance-weighting, subspace mapping, domain-invariant projections, feature augmentation, minimax estimators and robust algorithms. A number of points will arise, which I will discuss in the last section. I conclude with the remark that many open questions will have to be addressed before transfer learners and domain-adaptive classifiers become practical.","tags":["machine-learning","domain-adaptation","transfer-learning","covariate-shift","sample-selection-bias"],"title":"An introduction to domain adaptation and transfer learning","type":"publication"},{"authors":["J. Minnema","M. van Eijnatten","W.M. Kouw","F. Diblen","A.M. Mendrik","J. Wolff"],"categories":null,"content":"","date":1543650287,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543650287,"objectID":"9e3dd1b900be14bb402cdfb99f141760","permalink":"https://wmkouw.github.io/publication/bonectcnn/","publishdate":"2018-12-01T09:44:47+02:00","relpermalink":"/publication/bonectcnn/","section":"publication","summary":"OBJECTIVES: The most tedious and time-consuming task in medical additive manufacturing (AM) is image segmentation. The aim of the present study was to develop and train a convolutional neural network (CNN) for bone segmentation in computed tomography (CT) scans. METHODS: The CNN was trained with CT scans acquired using six different scanners. Standard tessellation language (STL) models of 20 patients who had previously undergone craniotomy and cranioplasty using additively manufactured skull implants served as “gold standard” models during CNN training. The CNN segmented all patient CT scans using a leave-2-out cross-validation scheme. All segmented CT scans were converted into STL models and geometrically compared with the gold standard STL models. RESULTS: The CT scans segmented using the CNN demonstrated a large overlap with the gold standard segmentation and resulted in a mean Dice similarity coefficient of 0.92 ± 0.04. The CNN-based STL models demonstrated mean surface deviations ranging between -0.19 mm ± 0.86 mm and 1.22 mm ± 1.75 mm, when compared to the gold standard STL models. No major differences were observed between the mean deviations of the CNN-based STL models acquired using six different CT scanners. CONCLUSIONS: The fully-automated CNN was able to accurately segment the skull. CNNs thus offer the opportunity of removing the current prohibitive barriers of time and effort during CT image segmentation, making patient-specific AM constructs more accesible.","tags":["medical-imaging","deep-learning","additive-manufacturing"],"title":"CT image segmentation of bone for medical additive manufacturing using a convolutional neural network","type":"publication"},{"authors":null,"categories":null,"content":"Research institutions, hospitals, governments and companies are collecting all kinds of data at an increased rate. Such “big data” offers the possibility to increase our understanding of human behavior, improve clinical diagnosis, and create intelligent consumer products. However, data can also end up in the hands of parties that may take advantage of you. For example, Facebook user data was leaked to political campaigners to influence voters [1]. Central to this debate is the concept of trust: how can you trust that the data that you give out will not end up hurting you?\nThis debate was recently sparked by the adoption of the General Data Protection Regulation (GDPR), which gives individuals in the EU the right to review and destroy personal data collected by third parties. The GDPR greatly complicates the collection and dissemination of research data, particularly in medical sciences. How should researchers analyze data and publish their findings if their subjects decide that their data is to remain private? Can patient data be fully anonymized and yet remain traceable at the same time? And how does data protection and privacy fit within the principle of open science that encourages researchers to make their data Findable, Accessible, Interoperable, and Reusable (FAIR)?\nAn interesting novel technology in the data and trust debate is blockchain. The goal is to create a distributed transaction system without a central authority that profits from this position, for example the exchange of money without the intervention of a bank. Individual users can issue transactions that are subsequently verified by the entire community through a blockchain. If there’s foul play, for instance by someone changing their own balance, the transaction is rejected by the community. Blockchain thus ensures consensus between users that do not trust each other, which makes the technology interesting for a wide range of applications.\nIn this workshop, we will present different views on how big data is currently being used. Furthermore, we will initiate an interactive discussion with the audience during which the participants can answer questions and share opinions using their smartphones.\n[1] https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election\n","date":1536405486,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536405486,"objectID":"f54be9f9cacfa086dabea59e675e1470","permalink":"https://wmkouw.github.io/talk/nsfworkshop-bigdata/","publishdate":"2018-09-08T13:18:06+02:00","relpermalink":"/talk/nsfworkshop-bigdata/","section":"talk","summary":"Research institutions, hospitals, governments and companies are collecting all kinds of data at an increased rate. Such “big data” offers the possibility to increase our understanding of human behavior, improve clinical diagnosis, and create intelligent consumer products. However, data can also end up in the hands of parties that may take advantage of you. For example, Facebook user data was leaked to political campaigners to influence voters [1]. Central to this debate is the concept of trust: how can you trust that the data that you give out will not end up hurting you?","tags":["Data","trust","GDPR"],"title":"Big data \u0026 trust","type":"talk"},{"authors":["W.M. Kouw","M. Loog"],"categories":null,"content":"","date":1535022089,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535022089,"objectID":"e4007b1fb6409e7efae71240d3e27912","permalink":"https://wmkouw.github.io/publication/sskew-iwrisk/","publishdate":"2018-08-23T13:01:29+02:00","relpermalink":"/publication/sskew-iwrisk/","section":"publication","summary":"Importance-weighting is a popular and well-researched technique for dealing with sample selection bias and covariate shift. It has desirable characteristics such as unbiasedness, consistency and low computational complexity. However, weighting can have a detrimental effect on an estimator as well. In this work, we empirically show that the sampling distribution of an importance-weighted estimator can be skewed. For sample selection bias settings, and for small sample sizes, the importance-weighted risk estimator produces overestimates for datasets in the body of the sampling distribution, i.e. the majority of cases, and large underestimates for data sets in the tail of the sampling distribution. These over- and underestimates of the risk lead to suboptimal regularization parameters when used for importance-weighted validation. ","tags":["covariate-shift","cross-validation","sampling-skewness"],"title":"Effects of sampling skewness of the importance-weighted risk estimator on model selection","type":"publication"},{"authors":null,"categories":null,"content":"I presented my paper on how the importance-weighted risk estimator\u0026rsquo;s sampling distribution is skewed for small sample sizes. The weights effectively ensure an under- or over-estimation of risk, depending on whether the source distribution has larger or smaller variance than the target distribution, respectively. I explore how this affects hyperparameter selection during importance-weighted cross-validation.\n","date":1534756698,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534756698,"objectID":"d493ea0a6310fd4f92493d5d90897d46","permalink":"https://wmkouw.github.io/talk/icpr2018/","publishdate":"2018-08-20T11:18:18+02:00","relpermalink":"/talk/icpr2018/","section":"talk","summary":"I presented my paper on how the importance-weighted risk estimator\u0026rsquo;s sampling distribution is skewed for small sample sizes. The weights effectively ensure an under- or over-estimation of risk, depending on whether the source distribution has larger or smaller variance than the target distribution, respectively. I explore how this affects hyperparameter selection during importance-weighted cross-validation.","tags":["importance-weighted-risk","cross-validation","covariate-shift","sampling-skewness"],"title":"Effects of sampling skewness in importance-weighted cross-validation","type":"talk"},{"authors":["W.M. Kouw","M. Loog"],"categories":null,"content":"","date":1529563535,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529563535,"objectID":"6f99087f7dc10bea02297a292bc00b71","permalink":"https://wmkouw.github.io/publication/tcpr/","publishdate":"2018-06-21T08:45:35+02:00","relpermalink":"/publication/tcpr/","section":"publication","summary":"In many a realistic supervised learning scenario, the data distribution at test time differs, to a smaller or larger extent, from that of the original labeled training data. As a consequence, the so-called source classifier, trained on the labeled data, typically displays deteriorated performance on the test, or target data. Domain adaptation and transfer learning classifiers aim to alleviate this problem, but may often provide performance that is even worse than the non-adaptive classifier trained on the original training data. Here, we consider the setting of domain-adaptive supervised learning, in which a classifier is trained on both labeled data from a source domain and unlabeled data from a target domain to predict the corresponding target labels. Our primary contribution is that, in a very specific sense, we construct target robust parameter estimators for discriminant analysis that provably guarantee performance improvements of the target classifier over the source classifier.","tags":["domain-adaptation","robustness","discriminant-analysis"],"title":"Target contrastive pessimistic discriminant analysis","type":"publication"},{"authors":null,"categories":null,"content":"\nLibtlda is a library of classifiers designed for domain adaptation and transfer learning, available in Matlab and Python. It started out as the collection of classifiers that I implemented during my PhD, but is now being expanded with more methods and algorithms.\nInstallation has been made easy, and there are demos to help you get started. Coders familiar with sci-kit will find it easy to pick up.\nMore information is available on its documentation page.\n","date":1528564017,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528564017,"objectID":"0ab21211d334a19cc02646aaea399035","permalink":"https://wmkouw.github.io/project/libtlda/","publishdate":"2018-06-09T19:06:57+02:00","relpermalink":"/project/libtlda/","section":"project","summary":"Library of domain-adaptive classifiers and transfer learners.","tags":[],"title":"libTLDA","type":"project"},{"authors":null,"categories":null,"content":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on removing MRI-scanner based varation from images.\n","date":1525887531,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525887531,"objectID":"9ea9a9a81abfe8ad41df86e23ae80ce8","permalink":"https://wmkouw.github.io/talk/nvphbv2018/","publishdate":"2018-05-09T19:38:51+02:00","relpermalink":"/talk/nvphbv2018/","section":"talk","summary":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on removing MRI-scanner based varation from images.","tags":["representation-learning","feature-extraction","MRI"],"title":"MR acquisition-invariant representation learning","type":"talk"},{"authors":null,"categories":null,"content":"\nWhile I was at the Netherlands eScience Center, I worked on the Young eScientist Award 2016 project, together with its winner Maureen van Eijnatten and PhD student Jordi Minnema. They\u0026rsquo;re part of the 3D Innovation Lab under the department of Maxillo-Facial Surgery at the Vrije Universiteit medical center.\nDuring the project, we developed a method for automatically detecting bone tissue in medical CT-scanner images. This method consisted of an artificial neural network, called a convolutional neural network (CNN), which looks at individual voxels in the image plus their surroundings. If a voxel shows an intensity value suitable for bone tissue and is surrounded voxels with similar intensity values (noisy signal voxels are often isolated), then the network classifies that voxel as bone. It performs its function for a whole CT-scan, which allows us to automatically reconstruct a 3D model of the skull. This 3D model is later used to design and 3D-print saw templates and other constructs to aid surgeons.\n","date":1504977174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504977174,"objectID":"9759382dfd2796fc82ac26eccc65bf95","permalink":"https://wmkouw.github.io/project/ct-bone-seg/","publishdate":"2017-09-09T19:12:54+02:00","relpermalink":"/project/ct-bone-seg/","section":"project","summary":"Bone tissue recognition from CT-scans of maxillo-facial surgery patients.","tags":[],"title":"CT-bone-seg","type":"project"},{"authors":null,"categories":null,"content":"\nSuppose you have two sets of MR images, that were acquired using different scanners and/or different scanning protocols. One set of images is brighter and shows more tissue contrast than the other. One of them has annotations and the other does not. Tissue classifiers \u0026ndash; important to computer-aided diagnosis systems \u0026ndash; can be trained on the annotated data from one scanner, but when applied to data from the other scanner they will drastically under-perform. It is exactly what makes computer systems so powerful, i.e. looking at minute variations in pixel intensities, that also makes them vulnerable to data set shifts.\nWe developed a method called MR Acquisition-Invariant Neural Network that aims to learn a representation of patches such that these show minimal variation with respect to the MRI scanner without losing clinically-relevant tissue variation. Once trained, the network extracts acquisition-invariant feature vectors, which can be used for a variety of tasks in medical images later on.\nMore information is available on its documentation page.\n","date":1496333089,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496333089,"objectID":"60b752f8e01c22e789347b81fe65961e","permalink":"https://wmkouw.github.io/project/mrainet/","publishdate":"2017-06-01T18:04:49+02:00","relpermalink":"/project/mrainet/","section":"project","summary":"MR acquisition-invarant representation learning using Siamese neural networks.","tags":[],"title":"MRAI-net","type":"project"},{"authors":null,"categories":null,"content":"ICT.OPEN is the Dutch national conference for computer science in general. Researchers from various universities and companies present their work along different tracks.\nI presented my work in the Machine Learning track. My topic was cross-validation under covariate shift and how to reduce variance in the importance-weighted risk estimator.\n","date":1489079804,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489079804,"objectID":"3b58fc47ee57e9092bf91cdd84b9eb61","permalink":"https://wmkouw.github.io/talk/ictopen2017/","publishdate":"2017-03-09T19:16:44+02:00","relpermalink":"/talk/ictopen2017/","section":"talk","summary":"ICT.OPEN is the Dutch national conference for computer science in general. Researchers from various universities and companies present their work along different tracks.\nI presented my work in the Machine Learning track. My topic was cross-validation under covariate shift and how to reduce variance in the importance-weighted risk estimator.","tags":["machine-learning","covariate-shift","importance-weighting","variance-reduction"],"title":"Variance reduction techniques for importance-weighted cross-validation","type":"talk"},{"authors":null,"categories":null,"content":"I presented my paper on problems with importance-weighted cross-validation under covariate shift. Under covariate shift, the standard cross-validation estimator is not consistent (i.e. it won\u0026rsquo;t return optimal hyperparameter estimates). Importance-weighting the cross-validation estimator was deemed to resolve this issue, but we show that it is still not consistent.\n","date":1481361495,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481361495,"objectID":"ce9cc4f9daa9d554df50e4877c5d0b65","permalink":"https://wmkouw.github.io/talk/icpr2016/","publishdate":"2016-12-10T11:18:15+02:00","relpermalink":"/talk/icpr2016/","section":"talk","summary":"I presented my paper on problems with importance-weighted cross-validation under covariate shift. Under covariate shift, the standard cross-validation estimator is not consistent (i.e. it won\u0026rsquo;t return optimal hyperparameter estimates). Importance-weighting the cross-validation estimator was deemed to resolve this issue, but we show that it is still not consistent.","tags":["cross-validation","covariate-shift"],"title":"On cross-validation under covariate shift","type":"talk"},{"authors":["W.M. Kouw","M. Loog"],"categories":null,"content":"","date":1480588890,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480588890,"objectID":"fd21f3090c6ff551eade84e32ba85f5f","permalink":"https://wmkouw.github.io/publication/covshift-l2reg/","publishdate":"2016-12-01T12:41:30+02:00","relpermalink":"/publication/covshift-l2reg/","section":"publication","summary":"This paper identifies a problem with the usual procedure for L2-regularization parameter estimation in a domain adaptation setting. In such a setting, there are differences between the distributions generating the training data (source domain) and the test data (target domain). The usual cross-validation procedure requires validation data, which can not be obtained from the unlabeled target data. The problem is that if one decides to use source validation data, the regularization parameter is underestimated. One possible solution is to scale the source validation data through importance weighting, but we show that this correction is not sufficient. We conclude the paper with an empirical analysis of the effect of several importance weight estimators on the estimation of the regularization parameter.","tags":["cross-validation","covariate-shift","importance-weighting"],"title":"On regularization parameter estimation under covariate shift","type":"publication"},{"authors":["W.M. Kouw","L.J.P. van der Maaten","J.H. Krijthe","M. Loog"],"categories":null,"content":"","date":1477996402,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477996402,"objectID":"884d96bfc381538193f86239ebeabb5f","permalink":"https://wmkouw.github.io/publication/flda/","publishdate":"2016-11-01T12:33:22+02:00","relpermalink":"/publication/flda/","section":"publication","summary":"Domain adaptation is the supervised learning setting in which the training and test data are sampled from different distributions: training data is sampled from a source domain, whilst test data is sampled from a target domain. This paper proposes and studies an approach, called feature-level domain adaptation (FLDA), that models the dependence between the two domains by means of a feature-level transfer model that is trained to describe the transfer from source to target domain. Subsequently, we train a domain-adapted classifier by minimizing the expected loss under the resulting transfer model. For linear classifiers and a large family of loss functions and transfer models, this expected loss can be computed or approximated analytically, and minimized efficiently. Our empirical evaluation of FLDA focuses on problems comprising binary and count data in which the transfer can be naturally modeled via a dropout distribution, which allows the classifier to adapt to differences in the marginal probability of features in the source and the target domain. Our experiments on several real- world problems show that FLDA performs on par with state- of- the-art domain-adaptation techniques.","tags":["machine-learning","domain-adaptation","transfer-model"],"title":"Feature-level domain adaptation","type":"publication"},{"authors":null,"categories":null,"content":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on a robust estimator for linear discriminant analysis in domain-adaptive machine learning.\n","date":1464369513,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464369513,"objectID":"ab583c637ab232eef2cef0fe8e38ea0f","permalink":"https://wmkouw.github.io/talk/nvphbv2016/","publishdate":"2016-05-27T19:18:33+02:00","relpermalink":"/talk/nvphbv2016/","section":"talk","summary":"NVPHBV is the Dutch Society for Pattern Recognition and Image Processing. During their meetings, researchers from the Netherlands have a chance to present some of their work and catch up on developments in their fields.\nI presented my work on a robust estimator for linear discriminant analysis in domain-adaptive machine learning.","tags":["machine-learning","domain-adaptation","robust-estimator"],"title":"Target contrastive estimator for robust domain adaptation","type":"talk"},{"authors":null,"categories":null,"content":"\nIn domain adaptation, one is always required to make assumptions on how the two domains relate to each other. However, depending on the domain dissimilarity, these assumptions can be quite strong. Furthermore, they are often hard to support, even with labeled target samples. Unfortunately, when an assumption is invalid, the classifier can adapt itself in ways that are detrimental to performance. Therefore, in practice, it can be hard to predict whether a domain-adaptive classifier will perform well for a given problem setting.\nOur aim was to design a more robust method, one that makes no assumptions on the relationship between the domains, but is still guaranteed to never perform worse than the naive, non-adaptive classifier. We dubbed our resulting parameter estimator the Target Contrastive Pessimistic Risk estimator, after the estimator it was inspired on: Maximum Contrastive Pessimistic Likelihood.\n","date":1462118701,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462118701,"objectID":"f19c417b15d53a56763956cfb21d1914","permalink":"https://wmkouw.github.io/project/tcpr/","publishdate":"2016-05-01T18:05:01+02:00","relpermalink":"/project/tcpr/","section":"project","summary":"Target contrastive robust risk for safe domain adaptation.","tags":[],"title":"TCP","type":"project"},{"authors":null,"categories":null,"content":"ICT.OPEN is the Dutch national conference for computer science in general. Researchers from various universities and companies present their work along different tracks.\nI presented my first project, on feature-level domain adaptation, in the Natural Artificial Intelligence track.\n","date":1458463469,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458463469,"objectID":"d091db8729fe42c6e9971b53e8032f9d","permalink":"https://wmkouw.github.io/talk/ictopen2016/","publishdate":"2016-03-20T10:44:29+02:00","relpermalink":"/talk/ictopen2016/","section":"talk","summary":"ICT.OPEN is the Dutch national conference for computer science in general. Researchers from various universities and companies present their work along different tracks.\nI presented my first project, on feature-level domain adaptation, in the Natural Artificial Intelligence track.","tags":["machine-learning","domain-adaptation","transfer-model"],"title":"Feature-level domain adaptation","type":"talk"},{"authors":null,"categories":null,"content":"Suppose that data is collected according to a set of features, such as blood pressure in clinical research or word frequencies in natural language processing. Now, in the source domain, all these features are measured, while in the target domain, some values are missing or absent (i.e. words are not used in the target context). In this case, one could capture the relationship between the domains using a probabilistic model, an approach we have called feature-level domain adaptation. This \u0026ldquo;transfer model\u0026rdquo; describes the probability of observing a target sample, given that you have observed a particular source sample.\nWe designed a family of classifiers that perform domain adaptation by training with respect to a transfer model. Information dropout, as described in the example above, is one of the simplest and yet most widely applicable class of transfer models. We developed code for dropout transfer and applied it to settings with data missing-not-at-random, inactive regions of image space and word frequency reductions.\n","date":1448985905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448985905,"objectID":"9a9902be9a039cccd419994d13f7433a","permalink":"https://wmkouw.github.io/project/flda/","publishdate":"2015-12-01T18:05:05+02:00","relpermalink":"/project/flda/","section":"project","summary":"Feature-level domain adaptation using dropout transfer models.","tags":[],"title":"FLDA","type":"project"},{"authors":null,"categories":null,"content":"SNN organized a one day symposium entitled Intelligent Machines, where an overview of recent developments was presented. The meeting aimed to establish a dialogue and to build connections between academic research, industry and public institutions in the Netherlands.\nI presented my preliminary work on incorporating transfer models in domain-adaptive classifiers.\n","date":1426582830,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1426582830,"objectID":"14ad9d07fbad26b51cd8ac2c355073ae","permalink":"https://wmkouw.github.io/talk/snn2015/","publishdate":"2015-03-17T11:00:30+02:00","relpermalink":"/talk/snn2015/","section":"talk","summary":"SNN organized a one day symposium entitled Intelligent Machines, where an overview of recent developments was presented. The meeting aimed to establish a dialogue and to build connections between academic research, industry and public institutions in the Netherlands.\nI presented my preliminary work on incorporating transfer models in domain-adaptive classifiers.","tags":["machine-learning","domain-adaptation","transfer-model"],"title":"Feature absence regularization for domain-adaptive learning","type":"talk"}]