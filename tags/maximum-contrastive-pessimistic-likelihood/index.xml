<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Maximum-contrastive-pessimistic-likelihood on Researcher profile</title>
    <link>https://wmkouw.github.io/tags/maximum-contrastive-pessimistic-likelihood/</link>
    <description>Recent content in Maximum-contrastive-pessimistic-likelihood on Researcher profile</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 May 2016 18:05:01 +0200</lastBuildDate>
    
	<atom:link href="https://wmkouw.github.io/tags/maximum-contrastive-pessimistic-likelihood/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TCPR</title>
      <link>https://wmkouw.github.io/project/tcpr/</link>
      <pubDate>Sun, 01 May 2016 18:05:01 +0200</pubDate>
      
      <guid>https://wmkouw.github.io/project/tcpr/</guid>
      <description>In domain adaptation, one is always required to make assumptions on how the two domains relate to each other. However, depending on the domain dissimilarity, these assumptions can be quite strong. Furthermore, they are often hard to support, even with labeled target samples. Unfortunately, when an assumption is invalid, the classifier can adapt itself in ways that are detrimental to performance. Therefore, in practice, it can be hard to predict whether a domain-adaptive classifier will perform well for a given problem setting.</description>
    </item>
    
  </channel>
</rss>